{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "当学习新的pytorch使用方法时，在这里添加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# itertools\n",
    "一个高效的迭代器，还记得yield的迭代生成功能吧？itertools提供了更加丰富灵活的序列产生方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===数字产生器===\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "===字母循环产生器===\n",
      "a\n",
      "b\n",
      "c\n",
      "a\n",
      "b\n",
      "c\n",
      "a\n",
      "b\n",
      "c\n",
      "a\n",
      "===无穷循环===\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "print(\"===数字产生器===\")\n",
    "generator = count(2)\n",
    "for i in range(10):\n",
    "    print(next(generator))\n",
    "\n",
    "generator = count(5, 2)\n",
    "for i in range(10):\n",
    "    print(next(generator))\n",
    "    \n",
    "from itertools import cycle\n",
    "print(\"===字母循环产生器===\")\n",
    "generator = cycle(\"abc\")\n",
    "for i in range(10):\n",
    "    print(next(generator))\n",
    "\n",
    "from itertools import repeat\n",
    "print(\"===无穷循环===\")\n",
    "generator = repeat(\"i\")\n",
    "for i in range(10):\n",
    "    print(next(generator))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "当然也有有限迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "6\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "a\n",
      "b\n",
      "c\n",
      "A\n",
      "B\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "from itertools import accumulate\n",
    "for i in accumulate([1, 2, 3, 4]):\n",
    "    print(i)\n",
    "    \n",
    "from itertools import chain\n",
    "for i in chain([1, 2, 3], [2, 3, 4]):\n",
    "    print(i)\n",
    "    \n",
    "for i in chain(\"abc\", \"ABC\"):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# pytorch基础\n",
    "我们将练习，可以用于GPU训练的最基础类：标量Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000e+00 -8.5899e+09  0.0000e+00 -8.5899e+09  1.1210e-44\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00 -8.5899e+09  0.0000e+00 -8.5899e+09  4.2039e-45\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 0.9451  0.9439  0.8820  0.0143  0.0351\n",
      " 0.0037  0.8230  0.0785  0.9323  0.8221\n",
      " 0.1489  0.5827  0.6032  0.0532  0.3729\n",
      " 0.2564  0.6914  0.3004  0.6219  0.8102\n",
      " 0.1808  0.9670  0.3201  0.1664  0.4150\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor(5, 5) # 未初始化\n",
    "print(x)\n",
    "y = torch.rand(5, 5) # 随机初始化\n",
    "print(y)\n",
    "x.size() # 获取shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK，简单的Tensor加法操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 9.4512e-01 -8.5899e+09  8.8197e-01 -8.5899e+09  3.5128e-02\n",
      " 3.7267e-03  8.2298e-01  7.8545e-02  9.3233e-01  8.2209e-01\n",
      " 1.4892e-01  5.8272e-01  6.0317e-01  5.3193e-02  3.7286e-01\n",
      " 2.5644e-01  6.9143e-01  3.0036e-01  6.2186e-01  8.1016e-01\n",
      " 1.8077e-01 -8.5899e+09  3.2008e-01 -8.5899e+09  4.1501e-01\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 1.8345e+00 -8.5899e+09  1.2501e+00 -8.5899e+09  8.4351e-01\n",
      " 8.9268e-01  1.7973e+00  9.2037e-01  1.1638e+00  1.0744e+00\n",
      " 4.8442e-01  1.0974e+00  1.2266e+00  2.4995e-01  3.8067e-01\n",
      " 4.9555e-01  9.4416e-01  5.4582e-01  1.2454e+00  1.2449e+00\n",
      " 4.4154e-01 -8.5899e+09  1.0567e+00 -8.5899e+09  6.5854e-01\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x + y)\n",
    "z = torch.rand(5, 5)\n",
    "print(x + y + z)\n",
    "# error: print(torch.add(x, y, z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 8.8940e-01 -8.5899e+09  3.6810e-01 -8.5899e+09  8.0838e-01\n",
      " 8.8895e-01  9.7430e-01  8.4183e-01  2.3148e-01  2.5230e-01\n",
      " 3.3550e-01  5.1464e-01  6.2347e-01  1.9675e-01  7.8019e-03\n",
      " 2.3910e-01  2.5273e-01  2.4546e-01  6.2359e-01  4.3478e-01\n",
      " 2.6077e-01 -8.5899e+09  7.3657e-01 -8.5899e+09  2.4353e-01\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 8.8940e-01 -8.5899e+09  3.6810e-01 -8.5899e+09  8.0838e-01\n",
      " 8.8895e-01  9.7430e-01  8.4183e-01  2.3148e-01  2.5230e-01\n",
      " 3.3550e-01  5.1464e-01  6.2347e-01  1.9675e-01  7.8019e-03\n",
      " 2.3910e-01  2.5273e-01  2.4546e-01  6.2359e-01  4.3478e-01\n",
      " 2.6077e-01 -8.5899e+09  7.3657e-01 -8.5899e+09  2.4353e-01\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 8.8940e-01 -8.5899e+09  3.6810e-01 -8.5899e+09  8.0838e-01\n",
      " 8.8895e-01  9.7430e-01  8.4183e-01  2.3148e-01  2.5230e-01\n",
      " 3.3550e-01  5.1464e-01  6.2347e-01  1.9675e-01  7.8019e-03\n",
      " 2.3910e-01  2.5273e-01  2.4546e-01  6.2359e-01  4.3478e-01\n",
      " 2.6077e-01 -8.5899e+09  7.3657e-01 -8.5899e+09  2.4353e-01\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "\n",
      " 8.8940e-01 -1.7180e+10  3.6810e-01 -1.7180e+10  8.0838e-01\n",
      " 8.8895e-01  9.7430e-01  8.4183e-01  2.3148e-01  2.5230e-01\n",
      " 3.3550e-01  5.1464e-01  6.2347e-01  1.9675e-01  7.8019e-03\n",
      " 2.3910e-01  2.5273e-01  2.4546e-01  6.2359e-01  4.3478e-01\n",
      " 2.6077e-01 -1.7180e+10  7.3657e-01 -1.7180e+10  2.4353e-01\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#原位替换\n",
    "z1 = z\n",
    "z2 = z\n",
    "z3 = z\n",
    "z1 = z1 + x # => z = z + x\n",
    "print(z1)\n",
    "z2 = z2 + x\n",
    "print(z2)\n",
    "\n",
    "z3.add_(x)\n",
    "print(z3)\n",
    "z2 = z2 + x\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "你会发现，z1和z2加完后不相等，这因为z1和z2只是引用赋值，没有进行clone，所以z3调用add_时，对z的原值进行了修改\n",
    "z1没有影响z2是因为z1 + x 创造了新的Tensor，所以没有影响z的原值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "当然，torch拥有和numpy一样的多维数组索引提取技术"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0\n",
      " 0  0\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x[2:4, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 3\n",
      "[torch.LongTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 从numpy转换过来\n",
    "import numpy\n",
    "a = numpy.asarray([1, 3])\n",
    "print(torch.from_numpy(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "大量的操作方法，参考 [doc](http://pytorch.org/docs/master/torch.html)\n",
    "\n",
    "还有矩阵操作 sum, mean, std, max, min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "torch比较二逼的地方是为了灵活，把cuda暴露出来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 自动梯度计算 autograd\n",
    "autograd包，Variable也在这个里面是整个包的核心\n",
    "\n",
    "Variable其实一个管理类，首先他的核心是一个标量Tensor，叫data，同时为它配备了一个反向传播时需要的梯度记录，叫grad。\n",
    "Function是autograd包中另一个非常重要的类。比如grad的计算就需要一个Function叫grad_fn，grad_fn记录了变量的创建过程，这样，未来反向传播时就会对grad_fn进行求导，所以这里要吐槽的是，grad_fn这个名字起得太恶心，叫forward_fn更好一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1  1  1  1\n",
      " 1  1  1  1  1\n",
      " 1  1  1  1  1\n",
      " 1  1  1  1  1\n",
      " 1  1  1  1  1\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "Variable containing:\n",
      " 2  2  2  2  2\n",
      " 2  2  2  2  2\n",
      " 2  2  2  2  2\n",
      " 2  2  2  2  2\n",
      " 2  2  2  2  2\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "Variable containing:\n",
      " 5  5  5  5  5\n",
      " 5  5  5  5  5\n",
      " 5  5  5  5  5\n",
      " 5  5  5  5  5\n",
      " 5  5  5  5  5\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n",
      "Variable containing:\n",
      " 25  25  25  25  25\n",
      " 25  25  25  25  25\n",
      " 25  25  25  25  25\n",
      " 25  25  25  25  25\n",
      " 25  25  25  25  25\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "input = Variable(torch.ones(5, 5), requires_grad = True)\n",
    "print(input)\n",
    "d = torch.ones(5, 5)\n",
    "# ERROR: print(input + d)\n",
    "print(input + Variable(d))\n",
    "y = input + 4\n",
    "print(y)\n",
    "print(y * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "操作只能在Variable之间进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<torch.autograd.function.AddConstantBackward object at 0x1148958b8>\n"
     ]
    }
   ],
   "source": [
    "print(input.grad_fn)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "y有grad_fn，input没有，grad_fn代表变量的创建过程\n",
    "好，下面我们来求一下梯度咯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 75  75  75  75  75\n",
      " 75  75  75  75  75\n",
      " 75  75  75  75  75\n",
      " 75  75  75  75  75\n",
      " 75  75  75  75  75\n",
      "[torch.FloatTensor of size 5x5]\n",
      " Variable containing:\n",
      " 75\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "None\n",
      "None\n",
      "None\n",
      "Variable containing:\n",
      " 3.6000  3.6000  3.6000  3.6000  3.6000\n",
      " 3.6000  3.6000  3.6000  3.6000  3.6000\n",
      " 3.6000  3.6000  3.6000  3.6000  3.6000\n",
      " 3.6000  3.6000  3.6000  3.6000  3.6000\n",
      " 3.6000  3.6000  3.6000  3.6000  3.6000\n",
      "[torch.FloatTensor of size 5x5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "out.backward() # 反向求导\n",
    "print(out.grad) # 查看求导结果\n",
    "print(z.grad)\n",
    "print(y.grad)\n",
    "print(input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "由于y, z都没有requires_grad = True，所以导致没有grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method backward in module torch.autograd.variable:\n",
      "\n",
      "backward(gradient=None, retain_graph=None, create_graph=None, retain_variables=None) method of torch.autograd.variable.Variable instance\n",
      "    Computes the gradient of current variable w.r.t. graph leaves.\n",
      "    \n",
      "    The graph is differentiated using the chain rule. If the variable is\n",
      "    non-scalar (i.e. its data has more than one element) and requires\n",
      "    gradient, the function additionaly requires specifying ``gradient``.\n",
      "    It should be a tensor of matching type and location, that contains\n",
      "    the gradient of the differentiated function w.r.t. ``self``.\n",
      "    \n",
      "    This function accumulates gradients in the leaves - you might need to\n",
      "    zero them before calling it.\n",
      "    \n",
      "    Arguments:\n",
      "        grad_variables (Tensor, Variable or None): Gradient w.r.t. the\n",
      "            variable. If it is a tensor, it will be automatically converted\n",
      "            to a Variable that is volatile unless ``create_graph`` is True.\n",
      "            None values can be specified for scalar Variables or ones that\n",
      "            don't require grad. If a None value would be acceptable then\n",
      "            this argument is optional.\n",
      "        retain_graph (bool, optional): If False, the graph used to compute\n",
      "            the grads will be freed. Note that in nearly all cases setting\n",
      "            this option to True is not needed and often can be worked around\n",
      "            in a much more efficient way. Defaults to the value of\n",
      "            ``create_graph``.\n",
      "        create_graph (bool, optional): If true, graph of the derivative will\n",
      "            be constructed, allowing to compute higher order derivative\n",
      "            products. Defaults to False, unless ``gradient`` is a volatile\n",
      "            Variable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(y.backward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "那么我们也可以自定一个Function，那么就要提供forward和backward两个方法啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "def Exp(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        result = i.exp()\n",
    "        ctx.save_for_forward(result)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        result, = ctx.saved_variables\n",
    "        return grad_output * result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK, 我们大概了解了自动梯度相关的知识，下面就推进开始学习最喜欢的神经网络吧，别忘了nn的基础是autograd哦\n",
    "\n",
    "## 神经网络 torch.nn\n",
    "前馈神经网络FNN，是一个多层感知器网络MLP，对于有监督学习，我们一般讲损失函数定义在最后的输出层上，对于多分类问题，可以使用softmaxwithcrossentropy作为损失函数。\n",
    "\n",
    "整个训练的过程大致是这样的：\n",
    "- 初始化网络参数\n",
    "- 将训练数据分批次\n",
    "- 对于每个批次的输入\n",
    "    - 先进行前向传播，中间的激活层一般都要记下来，一直到输出层\n",
    "    - 计算输出层的误差，记录最后一层每个神经元的delta\n",
    "    - 将误差进行反向传播，从倒数第二层开始，计算各层的delta，进而依赖delta计算该层的grad\n",
    "- 均化该批次的grad\n",
    "- 更新整个网络的权重\n",
    "\n",
    "weight = weight - learning_rate * gradient\n",
    "\n",
    "下面先来一个复杂的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # 一个函数包，里面有一些工具函数\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "class Net(nn.Module): # TODOModule的概念\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # 一个输入频道，6个feature， 5x5的卷积核\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # conv1其实可以看成一个函数，后面会当函数一样调用\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # 线性变换，注意这些定义的顺序没有关系，现在还没有把这些层关联到一起，只是分别定义\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # max pool 1\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 2x2的pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # 没有异形尺寸，写一个2也可以\n",
    "        x = x.view(-1, self.num_flat_features(x)) # TODO 这是个什么玩意？好像是个维度转换 flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # 注意为了后面的softmax，这里要露出logits，不能加激活函数了\n",
    "        return x\n",
    "    \n",
    "    # 正常不用写backward，因为人家会自动算滴 \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # 除了batch的索引之外的维度信息全部取出来, d1 * d2 * d3 * d4 ...\n",
    "        num_features = 1\n",
    "        for dim in size:\n",
    "            num_features *= dim\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.1042 -0.1793 -0.1388  0.1053  0.0884\n",
      "  0.0719 -0.1042  0.0587 -0.0527  0.1563\n",
      "  0.0940 -0.0827  0.0610  0.1233 -0.0583\n",
      " -0.1769 -0.0884 -0.1536  0.0332  0.0880\n",
      " -0.0986  0.1952 -0.0860 -0.0616  0.0521\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.1395  0.0351 -0.0007  0.0033 -0.0597\n",
      "  0.1587 -0.1626 -0.0078 -0.0742  0.0679\n",
      " -0.0479  0.0209 -0.0968  0.0767 -0.1573\n",
      "  0.0466  0.1651 -0.0915  0.1011 -0.1826\n",
      " -0.1994 -0.0369 -0.0305 -0.1998 -0.0517\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.1137  0.1080  0.1185  0.0763 -0.0396\n",
      " -0.0560  0.1419  0.0876 -0.0083  0.1896\n",
      " -0.0410 -0.0134 -0.0269  0.1059 -0.1240\n",
      " -0.1557  0.1067 -0.0403  0.1092 -0.0554\n",
      " -0.1332 -0.1512 -0.1390  0.0155 -0.0458\n",
      "\n",
      "(3 ,0 ,.,.) = \n",
      " -0.1069 -0.1170  0.1542 -0.1885  0.1297\n",
      " -0.1433 -0.0722 -0.0406 -0.1468 -0.0461\n",
      "  0.1035 -0.0822 -0.0678 -0.1886 -0.0446\n",
      "  0.0443 -0.1143 -0.1898  0.0061  0.0060\n",
      "  0.1407 -0.0075  0.0408  0.1999  0.1607\n",
      "\n",
      "(4 ,0 ,.,.) = \n",
      " -0.0320  0.0532  0.1038  0.0607 -0.0032\n",
      "  0.1805  0.1050  0.1502 -0.1159 -0.0764\n",
      "  0.0252 -0.0240  0.1056 -0.1952  0.0753\n",
      "  0.0555 -0.1815 -0.0491 -0.1759  0.0467\n",
      "  0.0652  0.1289  0.1499  0.1233 -0.1392\n",
      "\n",
      "(5 ,0 ,.,.) = \n",
      "  0.1331  0.0918  0.1967 -0.1596  0.1062\n",
      "  0.0382 -0.0633 -0.1952 -0.1600  0.1890\n",
      "  0.1547 -0.0908 -0.1679  0.1155  0.0908\n",
      "  0.0728  0.1983  0.1456 -0.0981  0.0158\n",
      "  0.0156  0.1871  0.0655  0.1954 -0.1142\n",
      "[torch.FloatTensor of size 6x1x5x5]\n",
      ", Parameter containing:\n",
      "-0.1783\n",
      " 0.0401\n",
      "-0.1507\n",
      "-0.1158\n",
      "-0.1604\n",
      "-0.0260\n",
      "[torch.FloatTensor of size 6]\n",
      "]\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters()) # 一个非常复杂的结构，每一个元素是一个Tensor，代表了相应结构的内部权重信息\n",
    "print(len(params))\n",
    "print(params[:2])\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "下面我们看看这个网络怎样制造输出吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.0582 -0.1069 -0.1225 -0.1314 -0.0049 -0.1201  0.0164  0.0125 -0.0239 -0.0368\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK, 进行一次反向传播前，记得归零grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10)) # 随便制造个误差好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "torch只支持minibatch模式，如果想单一sample训练，batch_size设置为1就好了，使用input.unsqueeze(0)就可以模拟成minibatch模式\n",
    "nn.Module - 神经网络模块，其实就是神经网络的基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = net(input)\n",
    "target = Variable(torch.arange(1, 11)) # 随便制造个目标值好了\n",
    "criterion = nn.MSELoss() # 标准，生成一个MSE评价函数，均方差Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "MSE是个什么鬼呢？通常我们使用最小二乘法（Least Squared Method）进行模型训练的目的是寻找一条直线和他的待拟合样本之间的最小欧式距离。通过梯度下降我们可以去寻找这个最小点。LSM是一个寻找模型的最佳参数以匹配样本的方法。MSE是样本均方差，计算这个值，可以评价训练出来的模型的好坏。其实LSE这个方法就是用来最小化MSE的，只不过最小二乘的cost公式在课程中讲解时一般都没有开平方。到了torch这里，就干脆统一了，所以MSE既是criteron(评价函数)也是loss（损失函数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.9388\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.MSELossBackward object at 0x114895b88>\n"
     ]
    }
   ],
   "source": [
    "loss.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "好，下面开始反向传播，记得先清零grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "conv1.bias.grad.after backward\n",
      "Variable containing:\n",
      " 0.0210\n",
      " 0.1442\n",
      "-0.0624\n",
      " 0.0069\n",
      "-0.0628\n",
      "-0.0490\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print(\"conv1.bias.grad.after backward\")\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "看到没，grad算出来，突突就算出来了，多方便啊，但注意我们还没有update权重信息呢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "这里，好好讲解一下，前面没好好学，这里就看不懂了，sub_原位替换，不用说了 f是每一层的参数，每层参数都是一个Variable，注意Variable里面有什么来着data,如果选了requires_grad = True还会有一个grad的内部Variable\n",
    "\n",
    "这里f.data就是该层权重的数据，f.grad.data是该层计算出的梯度的数据\n",
    "\n",
    "OK，还有一点要清楚，这只是进行了一次反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "前面这个梯度下降是我们自己写出来的，但单纯的梯度下降算法是不实际的，我们还有很多先进的梯度优化器，比如AdamOptimizer SGDOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01) # 要更新的所有参数信息都交给算法了，剩下的事情由算法自己解决\n",
    "optimizer.zero_grad() # 等同于 net.zero_grad()\n",
    "output = net(input) # 前向\n",
    "loss = criterion(output, target) # 计算输出误差\n",
    "loss.backward() # Variable的反向传播函数，基于grad_fn自动算\n",
    "optimizer.step() # 更新梯度，厉害了吧，optimizer会特别随性的控制step，是迈大一点的步子，还是迈小一点的步子，以尽快寻找极值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Great, 我们完成了简单的网络搭建到网络训练过程，这里没有写minibatch的全过程，留作作业吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 数据和一次更完整的训练\n",
    "最佳的数据读取和利用过程是：load进来->归一化处理->载入nparray->转为Tensor->包装成Variable，注意网络的输入时Variable，这样方便统一处理，因为一个网络的输入可能是另一个网络的输出，如果输入输出不统一，这种组合就很麻烦。对于视觉问题，torch引入了torchvision包，提供便利的数据集和数据加载功能。这次我们使用torchvision引入CIFAR10数据集\n",
    "\n",
    "![](./cifar10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ]) #这是什么玩意儿\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download = True, transform = transform)\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 4, shuffle = True, num_workers = 2) # batch产生器\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download = True, transform = transform)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size = 4, shuffle = False, num_workers = 2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "Help on function make_grid in module torchvision.utils:\n",
      "\n",
      "make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0)\n",
      "    Make a grid of images.\n",
      "    \n",
      "    Args:\n",
      "        tensor (Tensor or list): 4D mini-batch Tensor of shape (B x C x H x W)\n",
      "            or a list of images all of the same size.\n",
      "        nrows (int, optional): Number of rows in grid. Final grid size is\n",
      "            (B / nrow, nrow). Default is 8.\n",
      "        normalize (bool, optional): If True, shift the image to the range (0, 1),\n",
      "            by subtracting the minimum and dividing by the maximum pixel value.\n",
      "        range (tuple, optional): tuple (min, max) where min and max are numbers,\n",
      "            then these numbers are used to normalize the image. By default, min and max\n",
      "            are computed from the tensor.\n",
      "        scale_each(bool, optional): If True, scale each image in the batch of\n",
      "            images separately rather than the (min, max) over all images.\n",
      "        pad_value(float, optional): Value for the padded pixels.\n",
      "    \n",
      "    Example:\n",
      "        See this notebook `here <https://gist.github.com/anonymous/bf16430f7750c023141c562f3e9f2a91>`_\n",
      "\n",
      "torch.Size([3, 36, 138])\n",
      "\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.5373  ...  -0.1059  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000 -0.7804  ...   0.5843  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 36x138]\n",
      "\n",
      "(36, 138)\n",
      "(36, 138, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfXmMXdd53++8fZt9OORwHYqkJIqUJdm0LVveEkeJvMAy\nkERxllZFXQhBUiQpUjROXSBwgQDpFjQtmiaK7VhN3XiJN3mPI9tRbEeyqX2hKO6LSM5w9pm3L6d/\nfN93v+/NvBkORYrDmZwfQMzjOffde8655973rb/Pee8REBAQELD2EVvtAQQEBAQEXB2EF3pAQEDA\nOkF4oQcEBASsE4QXekBAQMA6QXihBwQEBKwThBd6QEBAwDpBeKEHBAQErBNc0QvdOXePc+6wc+6o\nc+4jV2tQAQEBAQGXD/dqE4ucc3EALwO4G8BZAD8B8Mve+xev3vACAgICAlaKxBV8900AjnrvjwOA\nc+4zAO4FsOQLPZfL+d7e3iu4ZEBAQMA/PZw/f37ce7/hUsddyQt9C4Az5v9nAbx5uS/09vbigQce\nuIJLBgQEBPzTw8c+9rFTKznuNXeKOucecM4ddM4dLJVKr/XlAgICAv7J4kpe6K8A2Gb+v5Xb2uC9\nf9B7f8B7fyCXy13B5QICAgIClsOVvNB/AmCPc26ncy4F4EMAHr46wwoICAgIuFy8ahu6977hnPvX\nAL4NIA7gk977Fy73PHe/690AgHRWpfdEKgMASPJf+ky/PYk4/T8ej+vxCZpGLKa/T7VaHQBQLVei\ntvL8HACgWS4DALIJPUcmTud44uHvRm0x3wAAbH/jjVFbYdtWAMBnv/gdAMCfffLzUd+//Q8fBQD8\n1q//ko4N9UVz9i7JfxdHGEVNLe3z/LnlXNT2h3/4H9u+9/533RZ9bjWbfIpW1NZo0DhaLW2LJ2gc\njtuaraaOO5kCAMRies1YLN72PXuNRoPWysV0TZvcFjfnmJ+fBwBUatWorbu7BwCQTNI9KJXKUV8y\nRddq1nU95D437VzidI2Ekz6dSyuSW8zx3PZ3jx3CQhx4y118eEOvyTcmZu4BOELMrqmOkY+z99jT\nNRsNbavXaH/GwNfSYePi6HkAQCalazozOQMAePirX4najpwg86pHms5Z17VNxei+bx3qi9r6u7oA\nAIMDG6O2bZu7AQAFvhebbtgf9SWyBZmVToWn0GzqgI+cPQeL2R1v0f/IXuywfm2RdtLfMfjOLzqH\nfLLncNE4XYdTOT6FOUf00Sx+9DnG5zDjXg6XGzToFn/sOvXYZZ5EcSVOUXjvvwHgG1dyjoCAgICA\nq4MreqFfFcgvt/mFFYlOpC5qIyklkpC8SgsO8ba/gErymS6VJvu7SNI4c+I4HZPSvlKxCAC46YBK\nuieOHQEAFBsq5ec8ST/veNsdAIB0WrWI/TuH6fiJi1FbJi1ShY7NO/pOLObb/tL8aF5twnujKRNd\nEi0j0dfqDR6bzi/OWoxoMwBQ5+PEWZ01c4mnSdqLGSlfJNF0Jh21Vau0HnUeYy6f1XFUaN2cuWY+\nT9Jhoatn0Xgdb0erfTW4r15VabnOUmEqlYraEnGaa6Veo3Fk81Ffiudy/tzZqM13kKp1onR+Z/dk\nnO5Lq6HjiKRCJ8foPB2Lat6IbPK51bJaG5/P0TUrFdVOnnr8H6mrpvvv3PkLAICpyYmoLZ2i+RXL\ndI6mGXcsKWukm6eQpLUa7NL7jSbdxwQ/X0kjwcpadZRSl8ljiVlhXEZhz9vhOwsF9HZJerGFuFMe\nTUykanmIzNc8ZC66x6Lzmi0R8yKZ++ibevzidZBxuNgKJfnXCCH1PyAgIGCdILzQAwICAtYJVt3k\nkmLbSNI4KMWsYrUXaYvMK9aPwupRzPw+xVgFjzt1dBw9/BIA4NTxYwCAHdu2RH3dBVLRZ1GL2tJD\nZBYYufGGqC2RpfP2D5CT6Zab9kR9vknXL02qc6jGztxYQs0UzRado9UiVbpe1fj8Jjtz0VT9b3pq\nCgBQqaqzayGK5Xm9ZpXmUCrrIhW6yOnVMiqq52uwNWGB+krrXa+peaBWJXNAzTg0xWzj2aTUMuMW\nc5RLqGmkxnNo1NS0IE6sVouumTGmnyabcpLGbJMt0FyqFR1Hi80S2Sx9t1HX+yifu7rVzKO4sKhF\n9p01y8i8XJuhQBylYibTvRZZYzqYLuxxcTa3yXG5gpqKdu2ifffij9VJ5ivk2O/KqWmrDt5Pnu5V\noqHPQTJJn7vyhahteGiQrpXSsTXZ5JKUe+asScLx+c3Mffu4OyFmTGe+tfRxnc4hTe0ml07nEDOW\ndZTyM+dkf+t9jO6tMSVGcQjWNOPlfPLeWWxyaXPEyjsrtroycpDQAwICAtYJVl9CT9KveCphpOtY\nBwmdfyljkVSknYnY4l9R+QXOZVUyFkm0WCQpp1xRyXh4eAhAe/jk5iTlTSUSxhHWJGmvxqFhLRNO\n55o0joZXqdZVxLmiDkrHnxs1kqrLxdmor8IhlQ0jfZaKNM5KRZ1jC2GdnSJVZMxcms0Gj1fn4lia\niKdJgm4aabzJl2oZadJxuGKzQ5SZ3LNqqRj1NUQidTruFo+jaTxQ6ZQ4iWkOc3NzUd/E5DgAYNfu\nXVHb3CyF7lmpLMUhj46lwqaR0EWLqFa0bXBwCEsikt5s6Ci12X0nTvtIgrVhlK49dI762dlqwuMi\nOdDx/UuqVHvDHgqXnTp9Mmrry1P/uZKeo3R+mq9JbdWyaj+sqLbpFUkOg4wbZ3yT5xBPseQfU60q\nikzsEGa7HOImhHUZF/SCkMP28S6nAdhvJMz7QxyeCd67KRPC2qzQ/hQnNx1Ii1Q196rBbZHW75fX\nFGQOQUIPCAgICLgqCC/0gICAgHWCVTe5RDGuTTUFNMW8YtQiiT0Wb1PKxJA3I6eejZnmmNyEqnM3\n7iEH5u5dI9TXqJnj2SRhVKYmZ1dW5tThWJwlB2UyRUtnnXWtGl1/rqTHJySe2yy1mGaaDVL/Giaz\nr8mOx/K8nsOzYzDWWpx1Gl3bOCMbkilqTABidoibWN5E5LSi8dSMaoo6fTeTMbHekpFrnJwS11vh\nWHZ7D5J8/6wzVxxrcbNukgk7M0emlFRK+wYHB2hOdZPFKg5ys3slY7FWZdXXyCpxnl+3cTj6ZdYy\ncl4aQ4WslVW2xcykJgOdu2SxtkxWqHditjFjk/PGohToqC/VQ07cjdu3R21zY3ylip736FkyS9X5\nGbLZvXXew5KdDADJTI7HraaZGJtYUpIV2hZELvNabHZwy8Tz2+e3k7mmzt1x421N8edGnP7WrWmV\nvZbxtlOxucs8txJXnm7Rvrt4TBPYp0+epLEZk1ymtx8AkNy2W6/VT47jrm5ywDet0zVyrC6aUhsu\nbS66+ggSekBAQMA6wepL6Oy4aNRVYhIp0oaeSfhVLC4hVMahw7/qNsxMPs/N6jk0C024TmzWHx1f\nN21xdoSkjEOz5ulzaY6km94B5cgAO0/TeZUEE5yV5xomdIqvMc/S0+TEeNQnkrkVaCKH8DIOl5px\naMb5mjXjRI1xFmPSaDbVWo376LzWidpiibhpMiNlTHWjDSQ4S1HCTkUiBDRrTkIPASBbIAlwzmg9\nOdYCBgZIKqrXzD3I0ri94VWRDNGS0YQkVM17Godv6jiyLJFOszMVAFK1pUNARcJtC41lad3ZUDyR\nWL1w1ujxTV4je8sShgNnITxrR96st3DydG1QzpUKO/JbFd0zrUaVx8NjNc7OBA+gYWLy6sINVFcJ\nPZUnTSiRzPJcjLYWca64hU2AcZovhM30VmnVOLJbIl0bzSZB50u02HFr+WN4gZNGKZBh1Ns4h3jf\nlSnYoCFqDYDeFK3v3PxU1JZo0R4eHNL6EdVsF4+bjzFh1T5aDx2HOnMXhzJeS0k9SOgBAQEB6wTh\nhR4QEBCwTrDqJpcmm1qsOid6qs00U7WlndYSUPXWeqzifA5n1DOheG2KOm5VPVYdq4YIKcYOrURF\n1cpHv/sDAMDmEaLR7R0cjPrEXFM114wUTWOKqBclzprO282OFwDIcaZeuagx8iU2w1jSqoXI5Y25\nhP+mTBxwVZyixhmZYJU+nSMTUb2qc5f1bloVktXOhiGQinHcdG1BpiYAtGJkYsgX9MbU2MxTKHRF\nbWkeksTZWy3ex9kUVrdja88sBYAG9wvFcMY4VmvsLMzk9JpxY1pbjMW0rkK8ZamDxaQk1iAb++68\nOEDNWdkR22paM4U4VuUgvaY4uvN53R8vF8m88uyz6ugTc9dALzlRq8bUVuNrlosa2z/NxF6FlJqd\n8r00LzFntZkOog/GhCLUwVgasVin51chJHzOmGZifN9cnU1tuqRwTiiazUmEGM0sdIJNTrMcwNA7\noBnChUH6HO/X5yXdS+Ymn1Nnf5xNk3ExhZmXS4dbZUwui52nKza5XC71bgcECT0gICBgneCSErpz\n7pMA3g9gzHu/n9v6AXwWwAiAkwDu895PLXWOZcHijXVAJZhHIm5+njkCKfp1FscfoNSq9pdQaENt\nVJUUY2jKxczxLdEQ4npeST7zNc1+/Ma3vgUAuOd97wUA3Pr6A3o8S7/ZuBm3ZJZWta1SIakpyaJp\nrqASWD1Fx7UMFWuTJZ32H/Bi2/8aJuxTnKhWWkhFoYZ6ljQ7C6WQSM1kp6Z5/VKGVwU8jqyRqJox\nGSct1vS4OusSTJXbMqml2VyBz6tcJJV5dl61aguHiHl2PttQRlHIkpauVsL/WBNyTsedydDnoslA\njZvrL8ZijU+2SsusM5oiodM1a5ZrRyQ7E8YpTm3rYIs4c9hx7E0InwQHzM3quJ96hiTz02eUL6i3\nl0PrUiSZJ839qbCzvDij2cgzU7Ru3cO679IcXts+tnbEOkipyyWPxhPLc7k0uLvLzC9/hrJeZ1lr\nrPZo0EFSfNB2/8lja7WHOmm3xQlyhl4cPRn1bdpA0nhXl2prjvdwqmnO0ZKxs4ZoIzAX5bNSK9D2\nSlmibSFsJ51vaTfzpbESCf1TAO5Z0PYRAI947/cAeIT/HxAQEBCwirikhO69f9Q5N7Kg+V4A7+LP\nDwH4PoDfezUDaLFU1jTSTVwSMFoq1Uoyi0idtfpiG6gN6/NSiqxNCuckpqicmE5fuEBShsNiZpSY\n+J59/EdR2+QFqoP95GOPAwDe9a6fjfqyPSyRGn9Ag221MRMSmEqxdMCcLzVjH/YsdbqkjiPJuR7N\nZZI4GkayS/Ba2dSZGnNYlCfUNp9hDpcWSyF5U7hiep6ZIE0hkSTzfKRs8pXYNWVsSTtPGnh5btIM\nlK7fTBgpkucvZeN6u4zGwnZpSYYBgAJLkzCFR6o11o44SaRUM2yLLP2mMobFcZm1lKQ0K41XvRTh\nMHZhYYlkn4wN8YxsumYvzM/RPZiY0OIUo6MkRU5NTfPxeh/Fn3LoxZeitpdfpqIrGTOX+XlaU+Gq\nyZpi7E1+lipV3Q3FYpnnqVKq+JfEx5GI6flFMm+TJXm/LSehJ4zPR3wb1u6c53W+wTzLe3hrTTDr\n6dGG+mumeW81zN6R5U2a0ZUnaS0zrDlVTUi0cBplTXJcgrW1hN0f/BxKMpjdLfpKWayxWKH9csMW\no7J+Kzq6M16tDX2j9/48f74AYONyBwcEBAQEvPa4Yqeop1CAJX+nnXMPOOcOOucOSqmzgICAgICr\nj1cbtjjqnBv23p93zg0DGFvqQO/9gwAeBIDNmzcvevHXWR2yIXn1+mKejaQUEXCLnTaifraZXOSD\n+ckSfg/hgvAmg7HJYXfHn9FwsK9+5jM0npJmGO4cIKdKktXbb33py1Hfe37pPgBAKqNjzHBty6ZJ\nb6tzXGODs0ddUwfpxHRi6Trlcwczk8CGPjY5K7A4q6aOLDtgM2l1Mk2wmp9k72/NqRqazzNvi1EA\nG9w/O63rkWF6YjGBZbt6o75WnO6LNduIaWhkq/KTnHuFHHwznMk5N6cOvF4OxUNc1eEqZ4imDE9P\njfeMnKOrR8cR1SA1KnWrvjQVsZhj2gpciG2hQ/aolzBEY/Yql8mEePrU6ajt0KFDAIATx49HbZPT\ndA9KTDtsC4pI/VKbadvXR/cvk1Gn7hTfj6lZOsf4tK5fnKlyU8a8mEiT6cKGFUqmtpiNYobXR2iN\n2wt+tHMrdYINR9Q8UUM/zOa0ly4ejdqqKRrHm/fdCQDoiet+/fEZ2s9zZp+Koz5hwoJL46MAgDQb\nSvbffFPU1z80IIOL2qbKXLfW0F7XEvTdJD978bYXiXw2oZ0dKJfFNtPJ4NJx1SQTu1PfCvFqJfSH\nAdzPn+8H8JUrGENAQEBAwFXASsIW/xrkAB10zp0F8AcA/gjA55xzHwZwCsB9r3YAUjU+Zxw55trR\n58ixxeFrbdJ4xK1g+V3o+LpxVCWk8INIHMZR9Ik//wsAwD985etR20ZO1tmzR0vQTbxCv/633nIb\nAOD5gz+O+ro3bwYAvPOn3ha1VUSqNnORquyN5uJq6hK+ljThk1GJs+bSjrwpwweT5gSaWs2SXtA1\nCgXLQsgFF/j8VcuKyOsrzmIAcJyIVehS56kk9zQifhCVfDOcdFTIqzQ5zxL0qWMqlcm9lWSwmmFW\nFGk9kdL7ODNG7puzr2jo3oYtVIwkl6Z1q9vkJw6fm7howhaX8VOJ9NkWChdtLV1TLe5B5x+7OBr1\nPfUE7YtDLzwXtYkz0lk5Sq4lzI0mHLfMe6dspPY0h+jWWsZZOEsaizj/EoZUJpeje5XLagm6moSR\n2kolHIAQ8cK0lI8okj0NQ6U8X61lsmGM7zJiRLUMjJOvnAUAnDryYtR2kh3dNQ4iuOfu90Z9t/Gz\n/OSohuy22KFZnlFH8+xFClzo5XKRd771LVHf9i3k7rNcUGfGSUua9qrBjVdYi65xEIbRootReKPh\nOeIN4lfqAO142JVzvqwkyuWXl+h69xVfPSAgICDgqiFkigYEBASsE6w+lwurnE3DbyF8ErZNeDM6\n1W8UU0Eb14nEARvdOuGF+J7+Pvajx6O+r37+CwCAbSYGur+PHGsvHzsWtc0zT8bRE2QyOHlO1ey+\n50l1fOc73hG1tZjOtWkISkRNjbM5o97UmGmZQ8tGvrKqOTO7dJRQPKFmjQbTz8ZsnVE2O0wah5mo\nnQk2lyRN7VRh+50vG3WfTSj2vlQ5A7bO6ntF4qkB9HIBEWtiiKh9TVGPGnPIeHZUdfX0R32zszTe\nmIkJT3AW4dYdagpLpNrHZul2W3y/k0Z8sXHcCyEmIJvlKdpwKm3oh5nK9vChlwEAT/7kyahv0phf\ndIy0ryVTGADmOPKrJhmuxoIhlMi2Xuwkr6/l5Knx/ogcpmaMKTaTZY3ZS3haLP9JjPdbs8m1ci1t\ncqw93h5Qjp/lTC75lj6Pwm9k6YejfWGydnN95AQ/dp7iLA6fVgfyzbvJuVmq6305PUUJ6uemTurY\neG8dP3cGAHBh7Naob/MwmVwyOTUb7tw6DAAwli2Uy7QH2PKCkxMaCHBhls7faKuZSvej2cHk0imv\n9CrQtnREkNADAgIC1glWXUIXDolOTIJWChd+ik5RUiLBtFUPj6pZGEmDxc6TR0i6fvRv/y7q682S\nlHDHm94QtU2wo3HsgjrfEpxNWeafwk1bt+gYmV3w5ZdUot99E5W1MgmoqLHjpyEZhsZDIlOullWC\nHTtHTsA//4tPRW13ffDnYZE3RTXqtXLbXwBwjq6VMmJqPkcSXZGLTZjoOPT0knZi11Q0IevELRcp\nlEyk663btuo8+fhqVe9BjvldGkbKz3RleIzCa6IaS28fSestM7h0jiU6M95Tp0+2jTtpPHIzzFZp\n12i+vHTYoshP1nEmoWolwwfz2I8eAwA88/SzNH5zH1McGjg5o5Ld6Dg57oqGDbEsaypl76wmwtff\nPLzJzIWOL5X13nYzL0kPh67m84bHhpkHd+6+UedSpnvmYiqSiuM4KonndHGjMpGWCZKdog1btnAB\nrAM0LkU3DL9LN/O0tAyHSon5hESbeeaIZsnu2EbS9W3bleF0dpocq43KRb0W/z19mkJG/9N//m9R\n3/DQEABgkykaIkVaCqZYTf9GOk5CPHsGN0d9yTxpEU37ULP2n+ng1/QdXlqi2Sxmg7kyBAk9ICAg\nYJ0gvNADAgIC1glW3eTS6kCSJCpKytS/lLZah1qQSXa0xY2Toi71Mp0hWJqj736fKXCPv3Qo6tuz\nixxsR89oZt/zTIRkw7ldic4xy6ry7hu0UniWyZSeffp5vSabeXbtVQdek20F4nxzthCA1Ds11eKb\n7AT6lft+JWo7tWAdxJkFaFx0wRR0KHKcbs2utyO1vYdVX0uVK85FySKlsXEcv3Eobt+xgz7wcC9O\najxwmmOJLZFaimPpK7YeKI8pxaaUiokhlzlcMIRW5bIQWRnzUYHMKeJQd8apnM/ReC1Jk6WpXQjZ\na84oxJJB+eILagJ4MSLNYnOMIQSbHKPxzs1rzHSF94wtGiK1XptC/mUogYWCN2baerppfpbmdmQ7\nZd2eu0Bkco2aOs9bWTr+Asd8A8BAgb+b13PEOO8hESfzQ8w49yJzEAxkHy2zjqm0CUhgy0zSmPx6\nuuneHrZf4jWM8/6bmVAn+6FD9Dzu362Zn47Ju/rMu+LUGDlUNwxQjdDdu3ZFfRcvkmnGlK1FnQm4\n5k3AwATv0+1baX/fMbIj6hsXR70xpYjJMWFMUPK8dCqI0SGvNFpfQ2V32QgSekBAQMA6wapL6CIJ\n1tsoLllKtU7RJEkODZb2bKZoQiQY41eVslzeSE1P/OiHAIBnDx4EAGRM6JdUU3/hiGYwzpbouw1v\naHbZ2dbFbPtnjp2K+mIJcsht3q7S+N//PV1zbFolzL2vI6k+neYMUMvbwlmb6ZSGVUlxiu5+zfY7\ndaE9LK5cVqmsyZJr0jiae9nJMzevxzmWJiQEbnZeJZQEO6GLc3pfKryWUhADANKsHUmmb/+AOqyK\nJZKekibb9NxZkhQ3bVKnVJYdzZGj0qzHiZMUttbbr8fXWdKtlPXeVis09hJrUF0FQyHL2asN41jt\nKixd4KJD8TWMjdF6P/Occv2MjZPDs8jjLpsiJhJKaGl6JfQ2bWqo5bvpntZ4z8+bYg9o0brNlVT7\n2rVzBABgie5qzIki5f+s9iMOx4ZxNCcTXGQkqWuQyZBDNeboXlgN0XWoci+fl3PkDRlOo3iDjiyb\nQhvHD5OGvGtY7+3t+/cAAHr72SlveFtS/EyMFXV+Q+wwvunmvXpck477zOc+DwC4wWjRN+69BQCQ\n7rEOW/qbi+t6pHkdkhwscf7IU1Hf+fOs7aRVAx7aTk7nQveGqE3pcxfLzZ1yvkUzPNOhb6UIEnpA\nQEDAOkF4oQcEBASsE6y6yUWcU7YSuny2FWNExStwJmfMOIWE1MnbbFOuzn7OZHJ+6fNfBAAUL5L5\nwxKClaukwuaNqaO7m2Kgz17UWOIiO+wk3rSZUpXwmeeIiKlUNxl4bE54wRAQ/auhfw4A2L2LnFn1\nmqlo7yUTNmpCqcSERU1VNRcildIY6yTH/I5dVFbjqQmpZqNqosTfNjkjMmnWdIZpXVNmPQoF+m5x\nXs0CRXb6Fdk8NWVIkkZ20vzGZ7TcrMQj103WYY5NAIUczT3RrVXapybI0Zc1Ib/opvvW3avHVXiN\n0ik2MRgyJaGktXVoXz4uzu/Fj0CCncrFWb3vzzxLseZHjmjmYrkiJjmO0zZmQMlUtnU4E0wKVzCV\noW7cQ+aAfA/N5bHHNHtZzGMVYzYUZ2g+r3v3xMmTAIB9t5A5oTinjsSJcXYCmjRIMcUJtTMAdHcT\nrWycnaM2szkivzPkcOIo7RTUIOjK6Nom+dmMFfW8P/nBdwAAuYyu2769IwCAFNMyJ5Jq3stmmHTO\nZFZ3d5Nppjunc/mZn3o7AOAHj1GlsS9+/WtRXyZDey3bbSpxMenYm/ffFrXd+4EPAADivJ9a5pqD\nhZ0AgErNrgc9m/1ppW1Oc4Uvcd7XTIZrg52olqSrtVz5pxUiSOgBAQEB6wSrLqGLTGhDgOLskIsn\nrHTDFbG9ZFeaghH8S5kxYWwXz5Fk95ef+Kuo7Qg7MLcxV0jceFH3jpAjs2qKWZxjCa2ZMRJjnSSB\nuRmSTKeqGmLXYkmqdEQdZ7t2UYjVTEmdQS8cImn9xt3sPDXjFp6P4pzJFJ2gX38/r2PDBuU7AYA5\nk8GovBwqDeXyBe4zED4VDu2UghuA0uYaug/Mzsxx2+J7lWBa46EhdXBF2Z2m4ns+TxqWzYQ9OU5S\nb4mdslUTU5blEMmekkpIPVw31IZZRnUywTxAtkwAh8o5s903bqQM37HZxZwrFT6XZIACwMEnyCkm\nNU4BYNdOouxNMS/IyVMaGnhxvMTX1DXt66Xw0NffarhFmHJZMka7C+r4rnI2aN0Ub5CVt5nVkikd\njwtnjd7lco3r586pdpdyJI2nM6qtpTmD1/NzZsM6I2rYDq68ZepbwCossgOOn9Kgg1fOk/uvXDZ7\nl1WxLdtpbW0iar3GobRG0ypw9m/chHYmeT1uP3AAAFAzz/nMFO2xtAmf9Ky9nDmr2uUPn6Rn+O6f\neSsAYP/NGvoIH721oqaL4xRsmDE0xRJCK6HWdUMLXeH7UjKaU6UZJPSAgICAAMZKClxsA/B/QIWg\nPYAHvfd/4pzrB/BZACMATgK4z3s/tdR5lkJTyrDZRAZJ7DBls6QquVCiWYk+wWFBM5NqO/x/f/Vp\nAMCPfvCDqG3vTrJ91fg4y5GxZROF9b1yWhNBmkz2/062yQHAW37uHgDAmTMk2b1ipLJjR4nDZWpS\nQ8pOnj4BAMgU1G4qeklDQrmqKvl86UtfBQA8/YRKhyW2U++/Sfk4diyQ0JMpy4VD69GVUs1CeFUS\nRqqNCYMlJw+lzW6Qo+aLppgAy4d5I0U2WHrs6yPJu2mLcLAW1devkuDJk1zU4MwrUdvoOWrzfC4r\n2VU4FDCV1vUbGCTpbccNmuyxeSuHi7E0Wa2q1DdXJqksm9Jx93a3r5/FD39Ettfnn9N7UOEwwZEd\nes2b+H5kmDtlfEK3//nztD+yxl6+Zw+F5G1l6RMATp0irfHsGVoDG767nROGxkZVi8hxGJ0tmLKT\nxzTQT5IVrK79AAAe+0lEQVT3UcM9tJVDArvy1hdC65DpUu6SJicURQyIlmmS5WvLrNhaTjRnxK3/\ngH1awqsDAGdGycezc0T5f6psZy6xRmaHIUlaF8eUt2WcE9myhrGx6eha2S7yMwwPaSjtLTv4Wqbc\n3Axrt5Mzutd/8uQTAICpKdL0L75di2Sk2DYuodQ0ztiicdTqpGFVa3TeYROq64Wd1CiS9Zh9R7w6\nrERCbwD4Xe/9LQDuBPCbzrlbAHwEwCPe+z0AHuH/BwQEBASsEi75Qvfen/feP8mf5wAcArAFwL0A\nHuLDHgLwwddqkAEBAQEBl8ZlOUWdcyMA7gDwOICN3vvz3HUBZJK5bEj9yLjJJhR6VstxohW0WY0z\nDrwLo6QWff0LX4rafvDoowCAoV4NI+rhUK9pDsmzNKPFIqnlM2VVuwaGifj+53/xl6K2PDv9du26\nGQBQN869U5zVeOyYmhNeeJH4J0Z2afboW+6iiubVOs3v6edejvo+8wUKsSoX1dka5xCnez74C1ga\nuh4Vpme1zqNEkhw0NsN2moslnDxLzqmbjUknz6r94Ea9rcUimR2sGcZz+OEFzgC12ZgtNoXNzakz\n96mnySHcMAUuWqyagtXWhslSHOKMwZKpd3rqFJmxnnpOOXN27SJz2pvfsB8AcPqUcvKMjdP+iMU1\n9vHAG96EpfDd730XAJAwZo2hfjLR9PRoAZQyZ4jGI+eXOkw9e/PyJjRWClAIrSsAPMGq/SybE3IZ\nVdlv2UvZj1uHlbr15Emae48J7byZjyvw/j6T1nlKqGalaPhdHJmn4mlTx5fXpiVV7o3ju8nFQryV\n/5xUrLC5ou1UunGz1xocgjxvMpq7BshENGvsDs+/RM/LiVNkNtq0yZhFt5K55Nbb1UQjJqpEQucc\n41DH0XF6PeWS+h45cOs+Oiam+6nMPEgVM3zP69DFTs6SKfRSrnCBkLg67+vsyHdOzb7lMpmXmlyv\ndc7cA8l2TmfVHDkwpFTcrxYrdoo65woAvgDgd7z3s7bPk9G7o1HNOfeAc+6gc+6gTVcOCAgICLi6\nWJGE7pxLgl7mn/bef5GbR51zw9778865YQBjnb7rvX8QwIMAsHnz5kUvfZHoEqbKfctLWTpbYEAk\nB/oNOn1SOVQ+9eDHAQAvGZ6NHDv/BkzySZkdMlJ6yybSVDm5Z8r86Lzzp38KANDVo1K+MvYxu5ph\nIxwYpONOnFI2ht27R+g44yz56sPfpPmxFPDVr3496itWWWNJGS4S/t09N62S8bYedfABKsUDym1T\nragEsWEjSYfVkiYxpZj7Q5x7eZOcIY6walUlE4m6ymfVeSPO1nqDxlhtmSQYdtQ++5yyWgpnScYk\nZHlHa1OvStV63Qvnx8lhVTMl0SS5yzJBXjhLUu/fz1P42PCm4ahv377b6ZpGci1EXC4mFJQxzsyO\nA0YKlkS1qmGCfOEsaWKDG0mK7OlV6T3N7H9poyWNMQvgkSPKLzjHvCSijdpEHXGGJ4ykO8FJcXkj\nyW/m67fYg5jr1v06yQEA80ZLOnWO2QiHt0dtuR6SlpOSoNYwRVdE8nY6Nsf7LZawMqHx8KF9T546\nQ9rr4SOqjXYz7491BI/wffu5d98NoF0j+srDDwMAnnzq6ahNEqw2DCqHyiB/brDG9IwpODPOzuod\nO3Tu3RxgkEwZziZhAOVghm1Gw85zcp4z4ZDiMG5PyOI+aTLaTIOdsnHTlnA2sOHV4ZISuqPwk08A\nOOS9/2PT9TCA+/nz/QC+csWjCQgICAh41ViJhH4XgH8G4DnnnPw0/nsAfwTgc865DwM4BeC+12aI\nAQEBAQErwSVf6N77H2Bplsx3X+kA/sf//FMAwBvfeCBqe91tlEm3Y0TjdZMJUn2OMZfGQ3/x8ajv\n8POk0nvjkKu0OPOuS1W2DCskk5yBN2tiYqeZ/2Kmos6SbXsoyzNlzCWyEnWpDG+yMXuYj2PrVlX3\nv/zlbwAAzpxVi9QPHyP6XseOKGdU6hjzfTRalieCdLfDR9XMtG3HPljYOpzC1eFNbPo8ZwracPU8\nZ8vNs7Om3FblnqlbTYGGXlbL831DUZvE0qfypEL2DGp8d7FY4fOrmaLIa+5z6pCulsiskmVHbMuo\nraLClitqCpNCJtaEMtjPWZgHXg8A6O/TGGvwmo5f1HjuakXntRBSl3TYZL1KsZWGydoUJ+iJ4ycB\nALtu2hn1bWS64pqhvj1zhkxx1peU5jj1yIRhrIwzXNG+UtL1kzj0zZvVgSYmiySbsRpeb3KTz1s2\nWYrHzpCzcNOGEzoONg1lu2ncaWPyk/3ZRgMbfVyaQHfsguZoSMDA4AaNCT/PtXLfeuDNUdvP3v2z\nAICtWziT96LGnJfZJDcxqfH+sqan0jqXDJtOZnlfb9ioz+Pbf/FDAIBb990RtYnp0VIMx9jEF0sx\nT1Rc59mMClcYE5T8NWskuTWx2GJTSpyfL2efuWV4cVaKkCkaEBAQsE6w6lwuUjDguRfVcbZ7N0k6\nA33q3HH8C3n2BDm/iuP6K53jjK2MkfqKJZLAvJFWBrjid2WO+kZNZt/oBEnQBZPFNzwyAgCoGumm\nFW+XSOIJdXo1mVNmzx4l1E8zyf/ho4fMt7gEXZMdlIYZMMnshi24BUcDs7NLF6eyHCM1lujThldC\nMh2dcWh6lkIazCXjjLaR5eMGBlWiqlVpvC8//6Rpo+tu2k5S0MyMjmNmliTLKZPBK6x1mwYMj0ic\nQ8NqUopO73s+Q23xpM5dVsaO7aabbuY50x6wAXRF1k66ulVqL5YWO0MF97zvXgBAj0mdPcuMhuNm\nLnk5H4fiTU1r3xBLhSeOqOQ4O0sOzZRxlOa5WIjwsdhYsS7W+BqGV+XWN5AGcsOuPVFb7yDt6xzz\nmty4V7WPpzks0pZnFE4Zu0qTF0jSLbBGketXqVYyLr2hBpRM0eXyRY8ceib6PDNJ968rp/vvF+6l\ndb7rzXdFbUm+fyKrHjmu6zfKfClVw38yxM/0r35ILb6SGfr9R/8BAPD8S+qIPXL0yKJxDm2gc2zd\npuGQqTxpQqIhdpqn6/C5nTBR/tPAQnRMtF2uWsgKEST0gICAgHWC8EIPCAgIWCdYdZNLkusadnWp\nE+b0aXKmvGjMMKKNdLFJoi+ljspeNi1UjNkhyZmRmbw6RXcylW1PgVT6Z57VOoFFzjzdd5PWJuzm\neFZLSiQfhUCsYcioEjFWF1sa6/3+978HADC8VU05o6OkmguZV72lKtmTT5Oaasnw5Wf3wuhJbcPb\nYZFIGFMKq8aVsjrT0mxCsQ6aOc7QlAxAm5k7epGyKzNmnTPsscuaCutFLl4xynHg2S51is7NiglC\n55JjYqh8Vq/lOaa6wfVLq2buVTbzoG4oddm0tm3HSNSW5KxHIXurGTNZje/RnKkg3/BillhMiPSG\nN5KTrjYzHrVJDsM5Y+qbYWdlL9cFTRhzXEmKgDg1DwjDayKpx20Yoj22ZTPTxZqt1sdx2ltGlLp1\nK8dPD/Rr3HUuR9cXNf51txsSMs6hKM4ac1A/mXKaFTU7zY+P8Tlo3QwvHiQdJGYaPReFaPmlHXnn\nz2hGbK5A5qC73vZWncsWMq22jMlRarDKXjx+TGPIJzk/IGY4nUeZuOyb3/pW1HbgjtcBAG5mM9wN\nHNwAAHU2M46Pq4N8epru8zgXUwGAffso6CAvZsvFXGVt8Av+XhKdznHl7LlBQg8ICAhYL1h1CV0K\nLxQNx4OUXIsZh2OKQ/GSHIJmktaQYceSdZbIedOm5JpkX27bSU7Lp1/QsnBFJs/fe5uWoXJ8/XrV\nlIjjX1bvpASXjkOEQltWangzhb5tn1KnXv8AOWHecic5uMSBCwDHj1MWoXXYSrX4qRmVIBbBXLMe\n8Z6YknxpWg9LaZpOkGQ8y4UlTI0ApFnDKRn+iWQPSVmxLpUAs8zRUeAIwtPnNDwznqb12zGilLP9\nfVxIoaLsETOzJP3Wa1ykoqWhfnXOnE0a2SPL/Bd1w+8yyesrjvTKvN6zGoejzZvSeT09ohEuFouE\nf6U5Z7L4pOiKDV9jHpsWaw+ZtKEVdnRPe/tUQ9y0eSu3qRazZQtJ3JuHqc8W7RB6VtE2AXWoRk5U\nAHLzRTPLGIqWXTeSxpk1Dt4Yz7k0o1L7aIpCYktFWqO4oStOcDikLafnWnQ+m8ELlGHxvve+T+fC\nIaZdJnO7wZqYdbbGOXt7gkM2rRNT+GDe8PrXR219nEl6/Kg6Pr/5jW/yuGkOb337O6O+jcwNM9Cv\nDvICaw92TTV0VvaHecD8opbomfcdxGwJX7Q9ovXbNr9y+X5JBAk9ICAgYJ0gvNADAgIC1glW3eQy\nz3S1lk5VHHdWvU2wbSPiAjL6zgxnGlrnothC2mKx2azS10PqVrpX1S7HREw7dmsMeY0Ju+yvntTp\nlPqNVk2KxdkhZ2piJplo6iZz3jOnKUNufIKy4KZn1BQQ1Rdt2exRvtYyXpO5aT2HEF/NmUxYGVPW\n0LkK5Wdxjswf09O6qDu2U6ZeX5+avaY4ltjF1c4k2Z2Tk2xq8Tr3NDu8R7ZpVuPQAKnIMzNav7HK\nTsscz71hSdkStC9shZxBzuBMJHQuFSbNkrqTU7O6HqWI7teco19MIe2EUgDgRB02cfndbGbavVvj\nv1M5cqwNsOPRUt/2dJNjrq9fzSvDW8jx2d2rbbFE+16PmUxDcfA2TQa07Otm0+z1qMKXZCbqOeJc\nk9XFF2cw5vuUmnYTO9UvjhLhWM1cM52J8XnVke3YBNpySwdPb9iocd01ZqiqmSCCaJyGLlnaXn6Z\nTCjnL9hqTXS/Txnyu9gO2lvveMc7dGzssBVisoa5jydOUFz77LTeg7vvJiKwQZPXIM9alA/SQfRt\nDzn37X/bung/maWSMrvB5BIQEBAQ0BGrLqGLVG1/6B3/oiUMPWWSf72SHCbVMpJgqUqOu5aJ+RKJ\nYG7OSL+MsXGSDnvML/KOOIU2SRgZAL26GVtE2i+XMmXJveOsMhPK5Vn6yJnwv907yUk4vIUkzWPH\ntSAGfJIvacLpopioxRlnAhNJiCRL0IP96oCa5XWYm1FNSEIIN3JmnQ0XTLBDLp1Wp/L0DBUdGBwa\niNqqVZJ+83nSdvr6TIV1DmnsN1S/SZYUewdUOixXuQ5ojTSXugmxK01SaF0jqc7CV86R1DbXoxpI\nFzsOT/I8c3mV3rdv5ir3WR33+LjU3VzMsxHjdL+4CY8bZmda75A6KPfsJeecaD09xtkpBUJypqao\nFByJtRV+IGmyXOM93Cat0vUTxkHZaoqT2PC1sLTe4r1o6Xaj58oyUYvGZyTuLGuoQzHaA9MTqkE1\nONggZeriNnmPu5bNyW2HUEEDQEOeCbOmrinn0H1Xb5GmdfQwBQe0DLVurkDrXK+ow7vMBWZuvVWD\nGfrZMS57fmZOgw5KXJSkp8tQI7Mzu1JdHILpY/xM2xTQToK0aEkd+/iPldBji2/Mchr4ShEk9ICA\ngIB1glWX0GMdbHBS+ithfu6yHFKUjGxV5ngWoWuGCc+xtH762EtR2z6WjM+xXW58/HzUt3cf2Uat\nVNbJJtmKbJhNHr/2CfuaDX+S4yyJf5XD7SSJomTCFovMuWK5N5rLSOYCM0QkmG2uWNJEK2GBy6b1\nwOI89ff3SoinSmDCsPfjx38UtY2MUIidLZZQZPt0kteqAVP2jsNEKxXD78L2+qqZ0jyHqDmWUoX3\nAwCqLL0PDamEPjvLSTBOQwIHNlGZtjhvaZv8lOREnvGLqgn1MaPiZEmlfEGc4zfT5hzC6dGMaduG\nrbSfegZIq3Mps35sx42Z6vJSlq5e1/C+JreJu8iy+klorvUlNaLv6QMgdREc7z9bNCHGMluzZW3X\n/NfsUwlZjYE1spaeY3KcEm9cTENYU6yBJFN6XxaiaMJK5blx9nnnKdjxjnNC24vPPgsAqJf1/rQ8\nre+eXVoq8b5foPKQQxvVTyNFVAp9ef6rl2xjjGTUeWwNU8wlUm2caBlWeu/AY+MXv8ekXGakEdnD\nr0YWUQcECT0gICBgnSC80AMCAgLWCS5pcnHOZQA8CiK9SAD4G+/9Hzjn+gF8FsAIgJMA7vPeTy11\nniUHIKYFU9QgxapKytgR0vw5xypT04Q/5dhpVDThSZ7PMTF6Lmo7d4p4IXxkjtEstH13EuF9MqlL\nIuqhNZcIYhHpv7a1IhXZOqy4QIPhVWlIdh2HrJ09q4UAquzwaXodR5JV/3pjaTXN1l8V5+aY4R2R\nUM1JUxygwPSvEjo3Zfqk0MbOGzT0TMIyYeaS4vXq7iL11mb8pjll0dZdbc0KX4ueo7efzB8D7MTd\nulNDA2fmybyTzJham+zYOnFcs1IvjJETb9tWMr1kcnoPpBhJX686SrPZxc5QQZxD+Lw3IYS8pomU\n3vD5OVqvrm6uMWn2QoJ5b2JGVZc7FDcV6sEOzVirg/ONh9gy+zqeEKpjO35qa/Gz5Iw5psXPScM8\nX6r7G4cc7+dYhsxvOVPgosGBC3NTxlHKJgPLlbQQ8fhiM8QC7yyNN26dxHStPs7ktBYSccTuv/nm\nqK2LKYNbxjnrFsQttF9dslNNr1hX2pzJrr3zkrLvwuNND5/rKrDjXhIrkdCrAH7ae38bgNsB3OOc\nuxPARwA84r3fA+AR/n9AQEBAwCphJSXoPADxTCT5nwdwL4B3cftDAL4P4PcuewAizZpEmiT/iqZN\nPa4UOytT7AFqtnGScKifSeyYY2eXM4LJmRMkkQ8wof1cUflE5Je7XjNV6/m8TSshxeNtf22Vdvnc\nltjBxxUKGronDHUvcGjWt7/97ahPrmULGIywM/d7j34PS0FCugCgyOFaTcOJItwzG0zpMnEQtZhF\nb2BAw+6aHKpWNKXf5udJIp2qKKdMIUGhl02WeCRcjy5K542ndD16emhNe7SGRSQB1tiJljal5ZBg\nB5SROjdw8QVfV4echBUOsIO32FBnWqVG69Gb1tJ5iaSs1+JCFwl29KULuh45/lwz9ztbIMk8wRqO\n9YtFvCfGlyZCYdI4I2X/Cy+M3WsS5tgwfCmeJe5WW6kz7uM1apPo4779IHMN15YUR2NKJGNtxwBA\nF4djWmbFmRleX6f7YyHSCVsKb9Ew4CNRWsexnZPQfuM3fh0AUK+oJlfnPVk32qgof8mkWQ/+21qQ\ncGU/d+Rc6SRDd3CiLjyXvWonp+ulv4slx3S5WNHVnXNxLhA9BuA73vvHAWz03kuYyAUAG5f47gPO\nuYPOuYO2lmJAQEBAwNXFil7o3vum9/52AFsBvMk5t39Bv8cSVMDe+we99we89wdyJu08ICAgIODq\n4rLi0L3308657wG4B8Coc27Ye3/eOTcMkt4vH6wmJowGIlmhVmVLSqw5Ow1tVmicHSM2bni+JNl+\n7aSVADDDmYgl49yTQNymUXtkcdLpxUUQxLxiTS6iMtWM2UZgzTCOdfODB6ne46FDh80w6EfPZrg+\nwzG5y1E9nDYx1l1Mi2trD4gj0Ru1coB5RiRGueF1/Q4dpuIiqYweP9si5229ppl6mSw5MisxWqOU\njaPmLLuq5bZhc0M6qWuaidPnM5zB22qpeWrbNiqCkDDFFarM/7PvFs326+oi80epSKaAjX3bo74K\nO2AnR01NVreMU1SyZLvVLiSO0rRxLua50IZQw7asfMROOhvrLc7KZie+D/5u3DiQI7+/GavwknjL\n28xLLrkLdmriFHWGijpy6JtcBzH9dKJ6jXHxkHy/KuENvh+zU0vXuc2YAINmXByDZn9gsbMwxp7g\nRIbWNNGjTleZX9NMsMzmqIrhnhHT19J3eMFVl/NW+uXPsvAkKzW5vFa45NWdcxucc738OQvgbgAv\nAXgYwP182P0AvvJaDTIgICAg4NJYiYQ+DOAh51wc9APwOe/915xz/wjgc865DwM4BeC+5U5yKSRN\n6FKKJRiT1IgkO0UdZzMKAT4A5FgCs45HFxdJw4ZJcSjjNDnCSqZMWaFP+D7ULOQ7hCtGLGytDuFP\n/CvdaCzO7LROJnEudRIMhCtmYnLCHE/fbS0jok+N6/F5zpobHlQnYKUh19SrVriYQalMGkXKOAEj\nNr+WbpEaS/m1sslcZEE7EzEU6pp1dZF0lTZV7hu8pk3DrilSkChk+aweX2ZNxbItCsNjOq7O0xhL\nbTFxWscMhwqvfTat502nl976UtAhbzy3ns+fMhK0aJWi9dgoPWGMbJn1jih5OlSGb3ZwqAvaHO+8\nd+JGe3Wu3ZFZN4Ve5GIxE0orDlDroazz/ZZiGjaEL84ZsFJcBgAyfB8tkyGK7bxJNmM61lq82xMs\nTybaIggl23Wx5u4iCV3HVufQ0iTaTgLA0C1ZLZpb2zTm6B6ZME7pi0JX7X3kvd7h2e+ETr7OZUgq\nrwgriXJ5FsAdHdonALz7tRhUQEBAQMDlI2SKBgQEBKwTrDo5lzh3EklVCdNsfkmYIPImxyqL8yjX\nZbL++HPTBP1KZlzTUMJW2Dl3bozIhpLZfNQ3uIlim62jSJx6y6GN9pf/k0qpKaCTacazOn77HUT5\nuXevViU/duyVtnMBhqhrmTjV/TfsjT4n2Ww0beqSFmfZeWXnxxSiMc5cLJqiEzfdQMUY7H3JX6Tt\ncvbiyagtVpAMSilWoDLC2AU6X8FSlbIaXjemGSnEUWATTbGoseFi/ug25rSIKKuu6yFFTqR+6PSs\n+uhrbFJyZrsXCkoLvBARmZLlY2LnujVFRIRXTqhTFxdvsPUyRStPJKyjTZzri/daPL748Yyzc7NT\nMYTIDON1/0Ukch2yIG1cucxFyMJcB5K6hHFyZjhizQYn4LxmPANA3WRzy3F2X8sc2mfevpbWjBXr\nUChC3h+WgldMOVHxjTbmWybMMrHsEo/vOjhKnetwTf7btG1tm6Ud0ZwvEWd+NcwwQUIPCAgIWCdw\nrxWNYyds3rzZP/DAA9fsegEBAQHrAR/72Mee8N4fuNRxQUIPCAgIWCcIL/SAgICAdYLwQg8ICAhY\nJwgv9ICAgIB1gmvqFHXOXQRQBDB+zS762mAQa3sOa338wNqfw1ofP7D257CWxr/De7/hUgdd0xc6\nADjnDq7EW3s9Y63PYa2PH1j7c1jr4wfW/hzW+vg7IZhcAgICAtYJwgs9ICAgYJ1gNV7oD67CNa82\n1voc1vr4gbU/h7U+fmDtz2Gtj38RrrkNPSAgICDgtUEwuQQEBASsE1zTF7pz7h7n3GHn3FHn3Eeu\n5bVfDZxz25xz33POveice8E599vc3u+c+45z7gj/7VvtsS4HLvL9lHPua/z/tTb+Xufc3zjnXnLO\nHXLOvWUNzuHf8B563jn31865zPU8B+fcJ51zY865503bkuN1zv0+P9eHnXM/tzqjbscSc/gvvI+e\ndc59Saqxcd91N4fLxTV7oXPFo/8F4D0AbgHwy865W67V9V8lGgB+13t/C4A7Afwmj/kjAB7x3u8B\n8Aj//3rGbwM4ZP6/1sb/JwC+5b2/GcBtoLmsmTk457YA+C0AB7z3+0HlLj+E63sOnwLVDrboOF5+\nJj4EYB9/50/5eV9tfAqL5/AdAPu9968D8DKA3weu6zlcFq6lhP4mAEe998e99zUAnwFw7zW8/mXD\ne3/ee/8kf54DvUi2gMb9EB/2EIAPrs4ILw3n3FYA7wPwcdO8lsbfA+AdAD4BAN77mvd+GmtoDowE\ngKxzLgEgB+AcruM5eO8fBbCwAvRS470XwGe891Xv/QkAR0HP+6qi0xy893/rvZcakY8B2Mqfr8s5\nXC6u5Qt9C4Az5v9nuW1NwDk3AirF9ziAjd7789x1AcDGJb52PeC/A/h3ACwD/1oa/04AFwH8JZuN\nPu6cy2MNzcF7/wqA/wrgNIDzAGa893+LNTQHxlLjXavP9r8E8E3+vFbn0IbgFF0BnHMFAF8A8Dve\n+1nb5ylM6LoMFXLOvR/AmPf+iaWOuZ7Hz0gAeD2A/+29vwNEHdFmmrje58C25ntBP06bAeSdc79m\nj7ne57AQa228C+Gc+yjIpPrp1R7L1cS1fKG/AmCb+f9Wbruu4ZxLgl7mn/bef5GbR51zw9w/DGBs\nqe+vMu4C8AHn3EmQieunnXP/F2tn/ABJSme994/z//8G9IJfS3P4GQAnvPcXvfd1AF8E8FasrTkA\nS493TT3bzrl/AeD9AH7Va9z2mprDUriWL/SfANjjnNvpnEuBHBAPX8PrXzYcFQP8BIBD3vs/Nl0P\nA7ifP98P4CvXemwrgff+9733W733I6D1/q73/tewRsYPAN77CwDOOOek8Oq7AbyINTQHkKnlTudc\njvfUu0H+mLU0B2Dp8T4M4EPOubRzbieAPQB+vArjuyScc/eATJAf8N6XTNeamcOy8N5fs38A3gvy\nLB8D8NFree1XOd63gdTKZwE8zf/eC2AA5OU/AuDvAPSv9lhXMJd3Afgaf15T4wdwO4CDfB++DKBv\nDc7hYwBeAvA8gL8CkL6e5wDgr0H2/jpIS/rwcuMF8FF+rg8DeM9qj3+ZORwF2crlef6z63kOl/sv\nZIoGBAQErBMEp2hAQEDAOkF4oQcEBASsE4QXekBAQMA6QXihBwQEBKwThBd6QEBAwDpBeKEHBAQE\nrBOEF3pAQEDAOkF4oQcEBASsE/x/7xiy4bg/bS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1190e1b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse  bird   cat plane\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(imgs):\n",
    "    print(imgs.size())\n",
    "    print(imgs[0])\n",
    "    imgs = imgs / 2 + 0.5 # unnormalize 反归一化，原值-1-1 =》 0-1\n",
    "    npimgs = imgs.numpy()\n",
    "    print(npimgs[0].shape)\n",
    "    timg = np.transpose(npimgs, (1, 2, 0))\n",
    "    print(timg.shape)\n",
    "    plt.imshow(timg) # 转置\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainLoader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "help(torchvision.utils.make_grid)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "这一段学习起来比较辛苦，make_grid基本没有人详细的解释他，下面就让我来给大家分析分析吧\n",
    "\n",
    "首先，什么是grid，其实就是图片网格，image grid，一组图片展示序列\n",
    "以上面的例子为例，输入是32x32的图片，做成网格后，加入padding，默认是2，所以高度变成了32 + 2*2 = 36, 我们有四张图片，所以宽度变成了4*32 + 5 * 2 = 138, 还有一个数是3，对于训练数据是放到前面的，但对于imshow需要放到后面，所以使用了transpose，OK，现在清楚了吧。不谢。\n",
    "\n",
    "### transforms\n",
    "接下来，我们回过头，啃前面那个更恶心的transforms\n",
    "transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])\n",
    "看着是不是想吐，什么东西？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Compose in module torchvision.transforms:\n",
      "\n",
      "class Compose(builtins.object)\n",
      " |  Composes several transforms together.\n",
      " |  \n",
      " |  Args:\n",
      " |      transforms (list of ``Transform`` objects): list of transforms to compose.\n",
      " |  \n",
      " |  Example:\n",
      " |      >>> transforms.Compose([\n",
      " |      >>>     transforms.CenterCrop(10),\n",
      " |      >>>     transforms.ToTensor(),\n",
      " |      >>> ])\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, img)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __init__(self, transforms)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(transforms.Compose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK, easy, Compose原来是个组合器，应该是一个流水线，本例中，transforms.toTensor()获得转换成Tensor的转换器，transforms.Normalize我们来看看是一个什么归一化工具，主要是参数不明白，为什么俩参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Normalize in module torchvision.transforms:\n",
      "\n",
      "class Normalize(builtins.object)\n",
      " |  Normalize an tensor image with mean and standard deviation.\n",
      " |  \n",
      " |  Given mean: (R, G, B) and std: (R, G, B),\n",
      " |  will normalize each channel of the torch.*Tensor, i.e.\n",
      " |  channel = (channel - mean) / std\n",
      " |  \n",
      " |  Args:\n",
      " |      mean (sequence): Sequence of means for R, G, B channels respecitvely.\n",
      " |      std (sequence): Sequence of standard deviations for R, G, B channels\n",
      " |          respecitvely.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, tensor)\n",
      " |      Args:\n",
      " |          tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor: Normalized image.\n",
      " |  \n",
      " |  __init__(self, mean, std)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(transforms.Normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK，比较清晰，连个参数分别是针对RGB三通道的期望mean和标准差std， channel = (channel - mean) / std\n",
    "好不容易，终于进入到下一个环节，定义一个网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # 还记得么？一个函数包 F.maxpool2d F.relu都在里面\n",
    "\n",
    "class Net(nn.Module): # 我觉得Module叫Network更实际，但Module可能更通用吧\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 这次不用F.maxpool2d了，这次提前定义好，注意这些东西不是层，而是一个函数，可以用在多个层中\n",
    "                                        # 其他的conv1具有独特性是因为他们的size太独特，难以用在其他地方，pool就很通用\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# OK，接着还是我们前面熟悉的，继续\n",
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "OK，下面重点来了，我们前面没有提到过的minibatch训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2): # 先做2次意思意思\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # 一次循环前，一定要zero哦，不能忘，pytorch太贱了，暴露了这么多，所以如果常用的东西还是要自己封装一下\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs) # 正向\n",
    "        loss = criterion(outputs, labels) # 输出误差 接收的是logits和predit_index\n",
    "        loss.backward() # 反向\n",
    "        optimizer.step() # 更新\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i % 200 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) # 居然用的是平均误差。。。真是良心作者\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 36, 138])\n",
      "\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.2392  ...   0.5059  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000 -0.5765  ...  -0.4275  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 36x138]\n",
      "\n",
      "(36, 138)\n",
      "(36, 138, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+P/jyitvLuJHGwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1193b6fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testLoader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship  ship  ship\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs.data, 1) # 就是argmax\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function max in module torch._C:\n",
      "\n",
      "max(...)\n",
      "    .. function:: max(input) -> float\n",
      "    \n",
      "    Returns the maximum value of all elements in the :attr:`input` Tensor.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input `Tensor`\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(1, 3)\n",
      "        >>> a\n",
      "    \n",
      "         0.4729 -0.2266 -0.2085\n",
      "        [torch.FloatTensor of size 1x3]\n",
      "    \n",
      "        >>> torch.max(a)\n",
      "        0.4729\n",
      "    \n",
      "    \n",
      "    .. function:: max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
      "    \n",
      "    Returns the maximum value of each row of the :attr:`input` Tensor in the given\n",
      "    dimension :attr:`dim`. The second return value is the index location of each\n",
      "    maximum value found (argmax).\n",
      "    \n",
      "    If :attr:`keepdim` is true, the output Tensors are of the same size\n",
      "    as :attr:`input` except in the dimension :attr:`dim` where they are of size 1.\n",
      "    Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting\n",
      "    in the output Tensors having 1 fewer dimension than :attr:`input`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input `Tensor`\n",
      "        dim (int): the dimension to reduce\n",
      "        keepdim (bool): whether the output Tensors have :attr:`dim` retained or not\n",
      "        out (tuple, optional): the result tuple of two output Tensors (max, max_indices)\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >> a = torch.randn(4, 4)\n",
      "        >> a\n",
      "    \n",
      "        0.0692  0.3142  1.2513 -0.5428\n",
      "        0.9288  0.8552 -0.2073  0.6409\n",
      "        1.0695 -0.0101 -2.4507 -1.2230\n",
      "        0.7426 -0.7666  0.4862 -0.6628\n",
      "        torch.FloatTensor of size 4x4]\n",
      "    \n",
      "        >>> torch.max(a, 1)\n",
      "        (\n",
      "         1.2513\n",
      "         0.9288\n",
      "         1.0695\n",
      "         0.7426\n",
      "        [torch.FloatTensor of size 4]\n",
      "        ,\n",
      "         2\n",
      "         0\n",
      "         0\n",
      "         0\n",
      "        [torch.LongTensor of size 4]\n",
      "        )\n",
      "    \n",
      "    .. function:: max(input, other, out=None) -> Tensor\n",
      "    \n",
      "    Each element of the Tensor :attr:`input` is compared with the corresponding\n",
      "    element of the Tensor :attr:`other` and an element-wise `max` is taken.\n",
      "    \n",
      "    The shapes of :attr:`input` and :attr:`other` don't need to match,\n",
      "    but they must be :ref:`broadcastable <broadcasting-semantics>`.\n",
      "    \n",
      "    .. note:: When the shapes do not match, the shape of the returned output tensor\n",
      "              follows the :ref:`broadcasting rules <broadcasting-semantics>`.\n",
      "    \n",
      "    :math:`out_i = max(tensor_i, other_i)`\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input `Tensor`\n",
      "        other (Tensor): the second input `Tensor`\n",
      "        out (Tensor, optional): The result `Tensor`\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "    \n",
      "         1.3869\n",
      "         0.3912\n",
      "        -0.8634\n",
      "        -0.5468\n",
      "        [torch.FloatTensor of size 4]\n",
      "    \n",
      "        >>> b = torch.randn(4)\n",
      "        >>> b\n",
      "    \n",
      "         1.0067\n",
      "        -0.8010\n",
      "         0.6258\n",
      "         0.3627\n",
      "        [torch.FloatTensor of size 4]\n",
      "    \n",
      "        >>> torch.max(a, b)\n",
      "    \n",
      "         1.3869\n",
      "         0.3912\n",
      "         0.6258\n",
      "         0.3627\n",
      "        [torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "total = 0\n",
    "for data in testLoader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(output, 1) # pytorch的发明者绝对是个简洁主义，希望一个函数搞定一切，连个argmax都懒得造\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.data == labels).long().sum()\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 在GPU上训练\n",
    "使用net.cuda()  inputs.cuda()  labels.cuda()\n",
    "\n",
    "Well, Great, 到现在我们应该算是pytorch入门了吧？好，我们现在终于可以回到lr.ipynb了，完成我们之前未尽的事业。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
