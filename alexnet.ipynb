{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# AlexNet\n",
    "让我们开始学习这个开启一个时代的神经网络\n",
    "原文地址：\n",
    "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
    "![](./img/alexnet.png)\n",
    "\n",
    "### 要点\n",
    "\n",
    "我们训练了一个大型深度卷积神经网络，对ImageNet LSVRC-2010竞赛的120万张高分辨率图片进行1000个类别的分类工作。在测试数据上，我们拿到了目前最好的成绩，top-1和top-5错误率分别为37.5%和17.0%。这个网络有6000万个参数，65万个神经元，构建了5个卷积层，其中一些卷积层后面跟了max-pooling层，最后是三个全连接层最后是使用softmax的1000个输出。为了让训练更快，我们使用了不饱和神经元(指的是ReLU)，并对卷积操作进行GPU优化实现。为了消减全连接层的过拟合， 我们采用了一种叫dropout的正则化方法，结果证明非常有效。\n",
    "\n",
    "We trained our models using stochastic gradient descent with a batch size of 128 examples, momentum of 0.9, and weight decay of 0.0005. We found that this small amount of weight decay was important for the model to learn.\n",
    "\n",
    "下面是第一层卷积核学习到的96个feature可视化：\n",
    "\n",
    "![](./img/alexnetlayer1.png)\n",
    "\n",
    "### AlexNet的历史贡献\n",
    "* 凸显了ReLU的重要价值\n",
    "* 引入了Dropout\n",
    "* 更深的网络层次\n",
    "\n",
    "### 本次实现的注意事项\n",
    "没有进行双GPU实现，所以网络没有进行拆分。现在的GPU的能力可以轻松覆盖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 64,11, stride = 4, padding = 2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(3, stride = 2),\n",
    "            \n",
    "            nn.Conv2d(64, 192, 5, padding = 2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(3, stride = 2),\n",
    "            \n",
    "            nn.Conv2d(192, 384, 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            \n",
    "            nn.Conv2d(384, 256, 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            \n",
    "            nn.Conv2d(256, 256, 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(3, stride = 2)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            # inplace=True means that it will modify the input directly, \n",
    "            # without allocating any additional output. It can sometimes slightly decrease the memory usage, \n",
    "            # but may not always be a valid operation (because the original input is destroyed). \n",
    "            # However, if you don't see an error, it means that your use case is valid.\n",
    "            \n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            \n",
    "            nn.Linear(4096, 200)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一次使用ImageNet，这个会很慢，必须上GPU了，同志们！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 1/6250 (0.02%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2973  (1.5892)\ttime: 0ms  (0ms)\n",
      "progress: 2/6250 (0.03%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3049  (2.7039)\ttime: 1513ms  (454ms)\n",
      "progress: 3/6250 (0.05%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3021  (3.4833)\ttime: 1351ms  (723ms)\n",
      "progress: 4/6250 (0.06%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2988  (4.0280)\ttime: 1490ms  (953ms)\n",
      "progress: 5/6250 (0.08%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2949  (4.4081)\ttime: 1503ms  (1118ms)\n",
      "progress: 6/6250 (0.10%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3015  (4.6761)\ttime: 1436ms  (1213ms)\n",
      "progress: 7/6250 (0.11%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2974  (4.8625)\ttime: 1508ms  (1302ms)\n",
      "progress: 8/6250 (0.13%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3015  (4.9942)\ttime: 1403ms  (1332ms)\n",
      "progress: 9/6250 (0.14%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3031  (5.0869)\ttime: 1231ms  (1302ms)\n",
      "progress: 10/6250 (0.16%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2959  (5.1496)\ttime: 1236ms  (1282ms)\n",
      "progress: 11/6250 (0.18%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2983  (5.1942)\ttime: 1297ms  (1287ms)\n",
      "progress: 12/6250 (0.19%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2953  (5.2245)\ttime: 1218ms  (1266ms)\n",
      "progress: 13/6250 (0.21%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2958  (5.2459)\ttime: 1190ms  (1243ms)\n",
      "progress: 14/6250 (0.22%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2986  (5.2617)\ttime: 1186ms  (1226ms)\n",
      "progress: 15/6250 (0.24%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3005  (5.2733)\ttime: 1176ms  (1211ms)\n",
      "progress: 16/6250 (0.26%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3021  (5.2820)\ttime: 1268ms  (1228ms)\n",
      "progress: 17/6250 (0.27%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2979  (5.2868)\ttime: 1298ms  (1249ms)\n",
      "progress: 18/6250 (0.29%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2932  (5.2887)\ttime: 1221ms  (1241ms)\n",
      "progress: 19/6250 (0.30%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3054  (5.2937)\ttime: 1222ms  (1235ms)\n",
      "progress: 20/6250 (0.32%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2992  (5.2954)\ttime: 1254ms  (1241ms)\n",
      "progress: 21/6250 (0.34%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3031  (5.2977)\ttime: 1434ms  (1299ms)\n",
      "progress: 22/6250 (0.35%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2977  (5.2977)\ttime: 1297ms  (1298ms)\n",
      "progress: 23/6250 (0.37%)\taccuracy: 0.00%  (0.00%)\tloss: 5.2976  (5.2977)\ttime: 1234ms  (1279ms)\n",
      "progress: 24/6250 (0.38%)\taccuracy: 6.25%  (1.88%)\tloss: 5.2981  (5.2978)\ttime: 1198ms  (1255ms)\n",
      "progress: 25/6250 (0.40%)\taccuracy: 0.00%  (1.31%)\tloss: 5.2918  (5.2960)\ttime: 1156ms  (1225ms)\n",
      "progress: 26/6250 (0.42%)\taccuracy: 0.00%  (0.92%)\tloss: 5.2963  (5.2961)\ttime: 1190ms  (1215ms)\n",
      "progress: 27/6250 (0.43%)\taccuracy: 0.00%  (0.64%)\tloss: 5.3003  (5.2973)\ttime: 1237ms  (1221ms)\n",
      "progress: 28/6250 (0.45%)\taccuracy: 0.00%  (0.45%)\tloss: 5.3068  (5.3002)\ttime: 1186ms  (1211ms)\n",
      "progress: 29/6250 (0.46%)\taccuracy: 0.00%  (0.32%)\tloss: 5.2932  (5.2981)\ttime: 1196ms  (1206ms)\n",
      "progress: 30/6250 (0.48%)\taccuracy: 0.00%  (0.22%)\tloss: 5.2984  (5.2982)\ttime: 1172ms  (1196ms)\n",
      "progress: 31/6250 (0.50%)\taccuracy: 0.00%  (0.15%)\tloss: 5.2981  (5.2981)\ttime: 1191ms  (1194ms)\n",
      "progress: 32/6250 (0.51%)\taccuracy: 0.00%  (0.11%)\tloss: 5.3012  (5.2990)\ttime: 1162ms  (1185ms)\n",
      "progress: 33/6250 (0.53%)\taccuracy: 0.00%  (0.08%)\tloss: 5.3049  (5.3008)\ttime: 1203ms  (1190ms)\n",
      "progress: 34/6250 (0.54%)\taccuracy: 0.00%  (0.05%)\tloss: 5.2943  (5.2989)\ttime: 1163ms  (1182ms)\n",
      "progress: 35/6250 (0.56%)\taccuracy: 0.00%  (0.04%)\tloss: 5.3076  (5.3015)\ttime: 1175ms  (1180ms)\n",
      "progress: 36/6250 (0.58%)\taccuracy: 0.00%  (0.03%)\tloss: 5.2990  (5.3007)\ttime: 1190ms  (1183ms)\n",
      "progress: 37/6250 (0.59%)\taccuracy: 0.00%  (0.02%)\tloss: 5.2923  (5.2982)\ttime: 1197ms  (1187ms)\n",
      "progress: 38/6250 (0.61%)\taccuracy: 0.00%  (0.01%)\tloss: 5.2948  (5.2972)\ttime: 1222ms  (1197ms)\n",
      "progress: 39/6250 (0.62%)\taccuracy: 0.00%  (0.01%)\tloss: 5.3051  (5.2996)\ttime: 1210ms  (1201ms)\n",
      "progress: 40/6250 (0.64%)\taccuracy: 0.00%  (0.01%)\tloss: 5.3042  (5.3009)\ttime: 1210ms  (1204ms)\n",
      "progress: 41/6250 (0.66%)\taccuracy: 6.25%  (1.88%)\tloss: 5.2951  (5.2992)\ttime: 1203ms  (1204ms)\n",
      "progress: 42/6250 (0.67%)\taccuracy: 0.00%  (1.32%)\tloss: 5.2920  (5.2970)\ttime: 1214ms  (1207ms)\n",
      "progress: 43/6250 (0.69%)\taccuracy: 0.00%  (0.92%)\tloss: 5.2933  (5.2959)\ttime: 1208ms  (1207ms)\n",
      "progress: 44/6250 (0.70%)\taccuracy: 0.00%  (0.64%)\tloss: 5.3010  (5.2974)\ttime: 1236ms  (1216ms)\n",
      "progress: 45/6250 (0.72%)\taccuracy: 6.25%  (2.33%)\tloss: 5.2993  (5.2980)\ttime: 1220ms  (1217ms)\n",
      "progress: 46/6250 (0.74%)\taccuracy: 0.00%  (1.63%)\tloss: 5.2942  (5.2969)\ttime: 1214ms  (1216ms)\n",
      "progress: 47/6250 (0.75%)\taccuracy: 6.25%  (3.01%)\tloss: 5.2972  (5.2970)\ttime: 1132ms  (1191ms)\n",
      "progress: 48/6250 (0.77%)\taccuracy: 0.00%  (2.11%)\tloss: 5.2996  (5.2977)\ttime: 1273ms  (1215ms)\n",
      "progress: 49/6250 (0.78%)\taccuracy: 0.00%  (1.48%)\tloss: 5.3058  (5.3002)\ttime: 1243ms  (1224ms)\n",
      "progress: 50/6250 (0.80%)\taccuracy: 0.00%  (1.03%)\tloss: 5.3038  (5.3013)\ttime: 1248ms  (1231ms)\n",
      "progress: 51/6250 (0.82%)\taccuracy: 0.00%  (0.72%)\tloss: 5.2948  (5.2993)\ttime: 1275ms  (1244ms)\n",
      "progress: 52/6250 (0.83%)\taccuracy: 0.00%  (0.51%)\tloss: 5.2907  (5.2967)\ttime: 1364ms  (1280ms)\n",
      "progress: 53/6250 (0.85%)\taccuracy: 0.00%  (0.35%)\tloss: 5.2936  (5.2958)\ttime: 1328ms  (1295ms)\n",
      "progress: 54/6250 (0.86%)\taccuracy: 0.00%  (0.25%)\tloss: 5.3122  (5.3007)\ttime: 1333ms  (1306ms)\n",
      "progress: 55/6250 (0.88%)\taccuracy: 6.25%  (2.05%)\tloss: 5.2945  (5.2989)\ttime: 1437ms  (1345ms)\n",
      "progress: 56/6250 (0.90%)\taccuracy: 0.00%  (1.43%)\tloss: 5.3031  (5.3001)\ttime: 1280ms  (1326ms)\n",
      "progress: 57/6250 (0.91%)\taccuracy: 0.00%  (1.00%)\tloss: 5.2932  (5.2981)\ttime: 1275ms  (1311ms)\n",
      "progress: 58/6250 (0.93%)\taccuracy: 0.00%  (0.70%)\tloss: 5.2959  (5.2974)\ttime: 1251ms  (1293ms)\n",
      "progress: 59/6250 (0.94%)\taccuracy: 0.00%  (0.49%)\tloss: 5.2886  (5.2948)\ttime: 1177ms  (1258ms)\n",
      "progress: 60/6250 (0.96%)\taccuracy: 0.00%  (0.34%)\tloss: 5.3044  (5.2977)\ttime: 1323ms  (1278ms)\n",
      "progress: 61/6250 (0.98%)\taccuracy: 0.00%  (0.24%)\tloss: 5.2966  (5.2973)\ttime: 1278ms  (1278ms)\n",
      "progress: 62/6250 (0.99%)\taccuracy: 0.00%  (0.17%)\tloss: 5.2912  (5.2955)\ttime: 1293ms  (1282ms)\n",
      "progress: 63/6250 (1.01%)\taccuracy: 0.00%  (0.12%)\tloss: 5.2960  (5.2956)\ttime: 1227ms  (1266ms)\n",
      "progress: 64/6250 (1.02%)\taccuracy: 0.00%  (0.08%)\tloss: 5.3002  (5.2970)\ttime: 1167ms  (1236ms)\n",
      "progress: 65/6250 (1.04%)\taccuracy: 6.25%  (1.93%)\tloss: 5.2926  (5.2957)\ttime: 1181ms  (1219ms)\n",
      "progress: 66/6250 (1.06%)\taccuracy: 0.00%  (1.35%)\tloss: 5.2956  (5.2956)\ttime: 1153ms  (1200ms)\n",
      "progress: 67/6250 (1.07%)\taccuracy: 0.00%  (0.95%)\tloss: 5.2984  (5.2965)\ttime: 1277ms  (1223ms)\n",
      "progress: 68/6250 (1.09%)\taccuracy: 0.00%  (0.66%)\tloss: 5.2836  (5.2926)\ttime: 1257ms  (1233ms)\n",
      "progress: 69/6250 (1.10%)\taccuracy: 0.00%  (0.46%)\tloss: 5.2982  (5.2943)\ttime: 1205ms  (1225ms)\n",
      "progress: 70/6250 (1.12%)\taccuracy: 0.00%  (0.32%)\tloss: 5.2924  (5.2938)\ttime: 1256ms  (1234ms)\n",
      "progress: 71/6250 (1.14%)\taccuracy: 0.00%  (0.23%)\tloss: 5.3057  (5.2973)\ttime: 1173ms  (1216ms)\n",
      "progress: 72/6250 (1.15%)\taccuracy: 0.00%  (0.16%)\tloss: 5.3144  (5.3024)\ttime: 1179ms  (1205ms)\n",
      "progress: 73/6250 (1.17%)\taccuracy: 0.00%  (0.11%)\tloss: 5.3018  (5.3022)\ttime: 1217ms  (1208ms)\n",
      "progress: 74/6250 (1.18%)\taccuracy: 0.00%  (0.08%)\tloss: 5.3035  (5.3026)\ttime: 1203ms  (1207ms)\n",
      "progress: 75/6250 (1.20%)\taccuracy: 6.25%  (1.93%)\tloss: 5.2950  (5.3003)\ttime: 1259ms  (1223ms)\n",
      "progress: 76/6250 (1.22%)\taccuracy: 0.00%  (1.35%)\tloss: 5.3023  (5.3009)\ttime: 1296ms  (1245ms)\n",
      "progress: 77/6250 (1.23%)\taccuracy: 0.00%  (0.95%)\tloss: 5.3012  (5.3010)\ttime: 1224ms  (1238ms)\n",
      "progress: 78/6250 (1.25%)\taccuracy: 0.00%  (0.66%)\tloss: 5.2949  (5.2992)\ttime: 1266ms  (1247ms)\n",
      "progress: 79/6250 (1.26%)\taccuracy: 0.00%  (0.46%)\tloss: 5.3003  (5.2995)\ttime: 1229ms  (1241ms)\n",
      "progress: 80/6250 (1.28%)\taccuracy: 0.00%  (0.32%)\tloss: 5.3053  (5.3013)\ttime: 1178ms  (1222ms)\n",
      "progress: 81/6250 (1.30%)\taccuracy: 0.00%  (0.23%)\tloss: 5.2998  (5.3008)\ttime: 1174ms  (1208ms)\n",
      "progress: 82/6250 (1.31%)\taccuracy: 6.25%  (2.03%)\tloss: 5.2932  (5.2985)\ttime: 1204ms  (1207ms)\n",
      "progress: 83/6250 (1.33%)\taccuracy: 0.00%  (1.42%)\tloss: 5.2952  (5.2975)\ttime: 1201ms  (1205ms)\n",
      "progress: 84/6250 (1.34%)\taccuracy: 0.00%  (1.00%)\tloss: 5.2982  (5.2977)\ttime: 1192ms  (1201ms)\n",
      "progress: 85/6250 (1.36%)\taccuracy: 0.00%  (0.70%)\tloss: 5.2964  (5.2973)\ttime: 1194ms  (1199ms)\n",
      "progress: 86/6250 (1.38%)\taccuracy: 0.00%  (0.49%)\tloss: 5.2933  (5.2961)\ttime: 1242ms  (1212ms)\n",
      "progress: 87/6250 (1.39%)\taccuracy: 0.00%  (0.34%)\tloss: 5.2986  (5.2968)\ttime: 1297ms  (1238ms)\n",
      "progress: 88/6250 (1.41%)\taccuracy: 0.00%  (0.24%)\tloss: 5.2985  (5.2974)\ttime: 1259ms  (1244ms)\n",
      "progress: 89/6250 (1.42%)\taccuracy: 0.00%  (0.17%)\tloss: 5.2800  (5.2921)\ttime: 1199ms  (1230ms)\n",
      "progress: 90/6250 (1.44%)\taccuracy: 0.00%  (0.12%)\tloss: 5.2950  (5.2930)\ttime: 1198ms  (1221ms)\n",
      "progress: 91/6250 (1.46%)\taccuracy: 0.00%  (0.08%)\tloss: 5.2988  (5.2947)\ttime: 1236ms  (1225ms)\n",
      "progress: 92/6250 (1.47%)\taccuracy: 0.00%  (0.06%)\tloss: 5.2986  (5.2959)\ttime: 1199ms  (1217ms)\n",
      "progress: 93/6250 (1.49%)\taccuracy: 6.25%  (1.92%)\tloss: 5.2765  (5.2901)\ttime: 1206ms  (1214ms)\n",
      "progress: 94/6250 (1.50%)\taccuracy: 0.00%  (1.34%)\tloss: 5.2997  (5.2930)\ttime: 1143ms  (1193ms)\n",
      "progress: 95/6250 (1.52%)\taccuracy: 0.00%  (0.94%)\tloss: 5.2876  (5.2914)\ttime: 1151ms  (1180ms)\n",
      "progress: 96/6250 (1.54%)\taccuracy: 0.00%  (0.66%)\tloss: 5.2922  (5.2916)\ttime: 1164ms  (1175ms)\n",
      "progress: 97/6250 (1.55%)\taccuracy: 0.00%  (0.46%)\tloss: 5.2907  (5.2913)\ttime: 1216ms  (1188ms)\n",
      "progress: 98/6250 (1.57%)\taccuracy: 0.00%  (0.32%)\tloss: 5.2983  (5.2934)\ttime: 1229ms  (1200ms)\n",
      "progress: 99/6250 (1.58%)\taccuracy: 0.00%  (0.23%)\tloss: 5.2930  (5.2933)\ttime: 1221ms  (1206ms)\n",
      "progress: 100/6250 (1.60%)\taccuracy: 0.00%  (0.16%)\tloss: 5.2980  (5.2947)\ttime: 1350ms  (1250ms)\n",
      "progress: 101/6250 (1.62%)\taccuracy: 0.00%  (0.11%)\tloss: 5.3044  (5.2976)\ttime: 1587ms  (1351ms)\n",
      "progress: 102/6250 (1.63%)\taccuracy: 0.00%  (0.08%)\tloss: 5.2977  (5.2976)\ttime: 1638ms  (1437ms)\n",
      "progress: 103/6250 (1.65%)\taccuracy: 0.00%  (0.05%)\tloss: 5.3021  (5.2990)\ttime: 1229ms  (1375ms)\n",
      "progress: 104/6250 (1.66%)\taccuracy: 0.00%  (0.04%)\tloss: 5.2986  (5.2989)\ttime: 1850ms  (1517ms)\n",
      "progress: 105/6250 (1.68%)\taccuracy: 0.00%  (0.03%)\tloss: 5.2903  (5.2963)\ttime: 1797ms  (1601ms)\n",
      "progress: 106/6250 (1.70%)\taccuracy: 0.00%  (0.02%)\tloss: 5.3148  (5.3018)\ttime: 1333ms  (1521ms)\n",
      "progress: 107/6250 (1.71%)\taccuracy: 0.00%  (0.01%)\tloss: 5.3070  (5.3034)\ttime: 1385ms  (1480ms)\n",
      "progress: 108/6250 (1.73%)\taccuracy: 0.00%  (0.01%)\tloss: 5.3023  (5.3031)\ttime: 1196ms  (1395ms)\n",
      "progress: 109/6250 (1.74%)\taccuracy: 0.00%  (0.01%)\tloss: 5.3079  (5.3045)\ttime: 1254ms  (1352ms)\n",
      "progress: 110/6250 (1.76%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3002  (5.3032)\ttime: 1175ms  (1299ms)\n",
      "progress: 111/6250 (1.78%)\taccuracy: 0.00%  (0.00%)\tloss: 5.3040  (5.3035)\ttime: 1198ms  (1269ms)\n",
      "progress: 112/6250 (1.79%)\taccuracy: 6.25%  (1.88%)\tloss: 5.2938  (5.3005)\ttime: 1221ms  (1255ms)\n",
      "progress: 113/6250 (1.81%)\taccuracy: 0.00%  (1.31%)\tloss: 5.2938  (5.2985)\ttime: 1422ms  (1305ms)\n",
      "progress: 114/6250 (1.82%)\taccuracy: 0.00%  (0.92%)\tloss: 5.3016  (5.2994)\ttime: 1498ms  (1363ms)\n",
      "progress: 115/6250 (1.84%)\taccuracy: 0.00%  (0.64%)\tloss: 5.2995  (5.2994)\ttime: 1200ms  (1314ms)\n",
      "progress: 116/6250 (1.86%)\taccuracy: 0.00%  (0.45%)\tloss: 5.3101  (5.3026)\ttime: 1177ms  (1273ms)\n",
      "progress: 117/6250 (1.87%)\taccuracy: 6.25%  (2.19%)\tloss: 5.2946  (5.3002)\ttime: 1389ms  (1308ms)\n",
      "progress: 118/6250 (1.89%)\taccuracy: 0.00%  (1.53%)\tloss: 5.2951  (5.2987)\ttime: 1362ms  (1324ms)\n",
      "progress: 119/6250 (1.90%)\taccuracy: 0.00%  (1.07%)\tloss: 5.2911  (5.2964)\ttime: 1341ms  (1329ms)\n",
      "progress: 120/6250 (1.92%)\taccuracy: 0.00%  (0.75%)\tloss: 5.2938  (5.2956)\ttime: 1226ms  (1298ms)\n",
      "progress: 121/6250 (1.94%)\taccuracy: 0.00%  (0.53%)\tloss: 5.2995  (5.2968)\ttime: 1507ms  (1361ms)\n",
      "progress: 122/6250 (1.95%)\taccuracy: 0.00%  (0.37%)\tloss: 5.2793  (5.2915)\ttime: 1384ms  (1368ms)\n",
      "progress: 123/6250 (1.97%)\taccuracy: 0.00%  (0.26%)\tloss: 5.2980  (5.2935)\ttime: 1245ms  (1331ms)\n",
      "progress: 124/6250 (1.98%)\taccuracy: 0.00%  (0.18%)\tloss: 5.2868  (5.2915)\ttime: 1378ms  (1345ms)\n",
      "progress: 125/6250 (2.00%)\taccuracy: 0.00%  (0.13%)\tloss: 5.2959  (5.2928)\ttime: 1345ms  (1345ms)\n",
      "progress: 126/6250 (2.02%)\taccuracy: 0.00%  (0.09%)\tloss: 5.2982  (5.2944)\ttime: 1330ms  (1341ms)\n",
      "progress: 127/6250 (2.03%)\taccuracy: 0.00%  (0.06%)\tloss: 5.2796  (5.2900)\ttime: 1434ms  (1369ms)\n",
      "progress: 128/6250 (2.05%)\taccuracy: 0.00%  (0.04%)\tloss: 5.3249  (5.3005)\ttime: 1184ms  (1313ms)\n",
      "progress: 129/6250 (2.06%)\taccuracy: 0.00%  (0.03%)\tloss: 5.2991  (5.3000)\ttime: 1188ms  (1276ms)\n",
      "progress: 130/6250 (2.08%)\taccuracy: 0.00%  (0.02%)\tloss: 5.3026  (5.3008)\ttime: 1174ms  (1245ms)\n",
      "progress: 131/6250 (2.10%)\taccuracy: 0.00%  (0.01%)\tloss: 5.3189  (5.3062)\ttime: 1369ms  (1282ms)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-28:\n",
      "Process Process-27:\n",
      "Process Process-31:\n",
      "Process Process-26:\n",
      "Process Process-29:\n",
      "Process Process-30:\n",
      "Process Process-25:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process Process-32:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 34, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/anaconda2/envs/aind/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-34c5b9c3a205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# train!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/trainer/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             self.call_plugins('iteration', i, batch_input, batch_target,\n\u001b[1;32m     74\u001b[0m                               *plugin_data)\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/utils/trainer/trainer.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-222c84af078e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 254\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda2/envs/aind/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     50\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     51\u001b[0m                _pair(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.trainer as trainer\n",
    "import torch.utils.trainer.plugins\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "model = AlexNet()\n",
    "\n",
    "# Data loading code\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                         std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "\n",
    "data_root = './tiny-imagenet-200'\n",
    "\n",
    "traindir = os.path.join(data_root, 'train')\n",
    "valdir = os.path.join(data_root, 'val')\n",
    "train = datasets.ImageFolder(traindir, transform)\n",
    "val = datasets.ImageFolder(valdir, transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size=16, shuffle=True, num_workers=8)\n",
    "\n",
    "# define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), 0.001, 0.9)\n",
    "\n",
    "\n",
    "# pass model, loss, optimizer and dataset to the trainer\n",
    "t = trainer.Trainer(model, criterion, optimizer, train_loader)\n",
    "\n",
    "# register some monitoring plugins\n",
    "t.register_plugin(trainer.plugins.ProgressMonitor())\n",
    "t.register_plugin(trainer.plugins.AccuracyMonitor())\n",
    "t.register_plugin(trainer.plugins.LossMonitor())\n",
    "t.register_plugin(trainer.plugins.TimeMonitor())\n",
    "t.register_plugin(trainer.plugins.Logger(['progress', 'accuracy', 'loss', 'time']))\n",
    "\n",
    "# train!\n",
    "t.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "这部分是从网上摘下来的很有借鉴意义，先留在这里。\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.trainer as trainer\n",
    "import torch.utils.trainer.plugins\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import resnet\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument('--data', metavar='PATH', required=True,\n",
    "                    help='path to dataset')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet18',\n",
    "                    help='model architecture: resnet18 | resnet34 | ...'\n",
    "                         '(default: resnet18)')\n",
    "parser.add_argument('--gen', default='gen', metavar='PATH',\n",
    "                    help='path to save generated files (default: gen)')\n",
    "parser.add_argument('--nThreads', '-j', default=2, type=int, metavar='N',\n",
    "                    help='number of data loading threads (default: 2)')\n",
    "parser.add_argument('--nEpochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--epochNumber', default=1, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--batchSize', '-b', default=256, type=int, metavar='N',\n",
    "                    help='mini-batch size (1 = pure stochastic) Default: 256')\n",
    "parser.add_argument('--lr', default=0.1, type=float, metavar='LR',\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weightDecay', default=1e-4, type=float, metavar='W',\n",
    "                    help='weight decay')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.arch.startswith('resnet'):\n",
    "    model = resnet.__dict__[args.arch]()\n",
    "    model.cuda()\n",
    "else:\n",
    "    parser.error('invalid architecture: {}'.format(args.arch))\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Data loading code\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomSizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],\n",
    "                         std = [ 0.229, 0.224, 0.225 ]),\n",
    "])\n",
    "\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "train = datasets.ImageFolder(traindir, transform)\n",
    "val = datasets.ImageFolder(valdir, transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train, batch_size=args.batchSize, shuffle=True, num_workers=args.nThreads)\n",
    "\n",
    "\n",
    "# create a small container to apply DataParallel to the ResNet\n",
    "torch.nn.parallel.data_parallel\n",
    "\n",
    "# 已经被废弃\n",
    "class DataParallel(nn.Container):\n",
    "    def __init__(self):\n",
    "        super(DataParallel, self).__init__(\n",
    "            model=model,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            gpu_ids = range(torch.cuda.device_count())\n",
    "            return nn.parallel.data_parallel(self.model, input, gpu_ids)\n",
    "        else:\n",
    "            return self.model(input.cuda()).cpu()\n",
    "\n",
    "model = DataParallel()\n",
    "\n",
    "# define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr, args.momentum)\n",
    "\n",
    "\n",
    "# pass model, loss, optimizer and dataset to the trainer\n",
    "t = trainer.Trainer(model, criterion, optimizer, train_loader)\n",
    "\n",
    "# register some monitoring plugins\n",
    "t.register_plugin(trainer.plugins.ProgressMonitor())\n",
    "t.register_plugin(trainer.plugins.AccuracyMonitor())\n",
    "t.register_plugin(trainer.plugins.LossMonitor())\n",
    "t.register_plugin(trainer.plugins.TimeMonitor())\n",
    "t.register_plugin(trainer.plugins.Logger(['progress', 'accuracy', 'loss', 'time']))\n",
    "\n",
    "# train!\n",
    "t.run(args.nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
